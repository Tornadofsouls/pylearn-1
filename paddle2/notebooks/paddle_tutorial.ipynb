{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paddle\n",
    "\n",
    "## general docs\n",
    "\n",
    "* https://www.paddlepaddle.org.cn/documentation/docs/en/guides\n",
    "* 高阶api: https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/quick_start/high_level_api/high_level_api.html\n",
    "* https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/index_cn.html\n",
    "\n",
    "## tricks of training for Paddldclas\n",
    "\n",
    "* https://paddleclas.readthedocs.io/en/latest/models/Tricks_en.html\n",
    "\n",
    "## install problems\n",
    "\n",
    "* core_avx.so: undefined symbol: _dl_sym, version GLIBC_PRIVATE\n",
    "* install lighting version.\n",
    "\n",
    "## Paddle dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "#### map-style, MapDataset\n",
    "\n",
    "* 映射式(map-style) 数据集需要继承这个基类,映射式数据集 可以通过一个键值 索引并获取指定样本的数据集,所有映射式数据集必须实现以下方法: \n",
    "* 1.___getitem__: 根据给定索引 获取数据集中指定样本,在 paddle.io.DataLoader 中需要使用此函数通过下标获取样本。  \n",
    "* 2.__len__: 返回数据集样本个数, <span style=\"color:red\">paddle.io.BatchSampler 中需要样本个数生成 下标序列。</span> \n",
    "* 可以直接继承 Dataset, 实现以上两个方法即可\n",
    "* MapDataset 进行了包装，比如可以直接传入list 数据集合\n",
    "\n",
    "\n",
    "#### iterable-style\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "* doc: https://www.paddlepaddle.org.cn/documentation/api/paddle/io/DataLoader_cn.html\n",
    "* 多进程读取： DataLoader支持单进程和多进程的数据加载方式，当 num_workers 大于0时，将使用多进程方式异步加载数据。\n",
    "* DataLoader当前支持 map-style 和 iterable-style 的数据集\n",
    "\n",
    "#### 禁用自动组batch\n",
    "* DataLoader 支持在 batch_size 和 batch_sampler 均为None的时候禁用自动组batch功能，此时需求从 dataset 中获取的数据为已经组好batch的数据，该数据将不做任何处理直接传到 collate_fn\n",
    "\n",
    "#### collate_fn 作用\n",
    "* 组batch的方法\n",
    "* collate_fn (callable) - 通过此参数指定如何将样本列表组合为mini-batch数据，当 collate_fn 为None时，默认为将样本个字段在第0维上堆叠(同 np.stack(..., axis=0) )为mini-batch的数据。默认值为None。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paddle BatchSampler\n",
    "\n",
    "* https://www.paddlepaddle.org.cn/documentation/docs/en/api/paddle/io/BatchSampler_en.html\n",
    "* Batch sampler used by paddle.io.DataLoader should be a subclass of paddle.io.BatchSampler, BatchSampler subclasses should implement following methods:\n",
    "    * __iter__: return <span style=\"color:red\">***mini-batch indices***</span> iterably. \n",
    "    * __len__: get mini-batch number in an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
      "[96, 97, 98, 99]\n",
      "[86, 42, 23, 54, 49, 71, 41, 55]\n",
      "[51, 11, 52, 45, 57, 0, 14, 26]\n",
      "[74, 99, 31, 64, 67, 85, 66, 6]\n",
      "[28, 75, 61, 72, 20, 47, 77, 32]\n",
      "[83, 19, 97, 89, 84, 63, 10, 96]\n",
      "[1, 36, 40, 48, 3, 7, 4, 98]\n",
      "[2, 30, 69, 50, 39, 43, 68, 59]\n",
      "[79, 94, 44, 34, 88, 76, 46, 58]\n",
      "[12, 5, 13, 92, 15, 25, 37, 82]\n",
      "[33, 80, 16, 95, 8, 73, 9, 91]\n",
      "[18, 87, 56, 27, 17, 65, 24, 60]\n",
      "[53, 38, 90, 21, 93, 62, 35, 81]\n"
     ]
    }
   ],
   "source": [
    "from paddle.io import RandomSampler, BatchSampler, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# init with dataset\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([784]).astype('float32')\n",
    "        label = np.random.randint(0, 9, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "bs = BatchSampler(dataset=RandomDataset(100),\n",
    "                  shuffle=False,\n",
    "                  batch_size=16,\n",
    "                  drop_last=False)\n",
    "\n",
    "for batch_indices in bs:\n",
    "    print(batch_indices)\n",
    "\n",
    "# init with sampler\n",
    "sampler = RandomSampler(RandomDataset(100))\n",
    "bs = BatchSampler(sampler=sampler,\n",
    "                  batch_size=8,\n",
    "                  drop_last=True)\n",
    "\n",
    "for batch_indices in bs:\n",
    "    print(batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/jeffye/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item 8/8 [============================>.] - ETA: 0s - 6ms/item"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Download finished\n",
      "Cache file /home/jeffye/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "data = paddle.vision.datasets.MNIST(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "paddle.vision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[10, 1], dtype=int64, place=Place(gpu:0), stop_gradient=True,\n",
       "       [[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cProfile import label\n",
    "\n",
    "labels = paddle.reshape(labels, shape=[-1, 1])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paddle layers \n",
    "\n",
    "### Cosine Similarity Operator - paddle.fluid.layers.nn.cos_sim(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[3, 1], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.83597958],\n",
      "        [0.93105304],\n",
      "        [0.85824275]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py:3792: DeprecationWarning: Op `cos_sim` is executed through `append_op` under the dynamic mode, the corresponding API implementation needs to be upgraded to using `_C_ops` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "x = paddle.rand(shape=[3, 7], dtype='float32')\n",
    "y = paddle.rand(shape=[1, 7], dtype='float32')\n",
    "out = paddle.fluid.layers.cos_sim(x, y)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [[0.8024077,0.9927354,0.27238318,0.8344984 ],\n",
    "        [0.48949873,0.5797396,0.65444374,0.66510963],\n",
    "        [0.1031398,0.9614342,0.08365563,0.6796464 ],\n",
    "        [0.1031398,0.9614342,0.08365563,0.6796464 ],\n",
    "        [0.10760343,0.7461209,0.7726148,0.5801006 ]]\n",
    "x2 = [[0.62913156,0.1536727,0.9847992,0.04591406],\n",
    "        [0.9098952,0.15715368,0.8671125,0.3156102 ],\n",
    "        [0.4427798,0.54136837,0.5276275,0.32394758],\n",
    "        [0.1031398,0.9614342,0.08365563,0.6796464 ],\n",
    "        [0.3769419,0.8535014,0.48041078,0.9256797 ]]\n",
    "x1 = paddle.to_tensor(x1)\n",
    "x2 = paddle.to_tensor(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[5], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0.10000000, 0.10000000, 0.10000000, 0.10000000, 0.10000000])\n",
      "Tensor(shape=[5, 5], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.10000000, 0.        , 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.10000000, 0.        , 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.10000000, 0.        , 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.10000000, 0.        ],\n",
      "        [0.        , 0.        , 0.        , 0.        , 0.10000000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = paddle.matmul(x1, x2, transpose_y=True)\n",
    "margin_diag = paddle.full(shape=[cosine_sim.shape[0]],\n",
    "                                  fill_value=0.1,\n",
    "                                  dtype=paddle.get_default_dtype())\n",
    "print(margin_diag)\n",
    "print(paddle.diag(margin_diag))     \n",
    "cosine_sim = cosine_sim - paddle.diag(margin_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[5, 1, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[0.80240768, 0.99273539, 0.27238318, 0.83449841]],\n",
      "\n",
      "        [[0.48949873, 0.57973957, 0.65444374, 0.66510963]],\n",
      "\n",
      "        [[0.10313980, 0.96143419, 0.08365563, 0.67964637]],\n",
      "\n",
      "        [[0.10313980, 0.96143419, 0.08365563, 0.67964637]],\n",
      "\n",
      "        [[0.10760343, 0.74612093, 0.77261478, 0.58010060]]])\n",
      "Tensor(shape=[1, 5, 4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[[0.62913156, 0.15367270, 0.98479921, 0.04591406],\n",
      "         [0.90989518, 0.15715368, 0.86711252, 0.31561020],\n",
      "         [0.44277981, 0.54136837, 0.52762753, 0.32394758],\n",
      "         [0.10313980, 0.96143419, 0.08365563, 0.67964637],\n",
      "         [0.37694189, 0.85350138, 0.48041078, 0.92567968]]])\n",
      "Tensor(shape=[5, 5], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [[0.52750373, 0.68519437, 0.90307665, 0.88645834, 0.94705576],\n",
      "        [0.75573283, 0.83689672, 0.97151995, 0.78222287, 0.95629632],\n",
      "        [0.23341376, 0.34393719, 0.75037485, 1.        , 0.92203134],\n",
      "        [0.23341376, 0.34393719, 0.75037485, 1.        , 0.92203134],\n",
      "        [0.67095637, 0.66773933, 0.91482407, 0.81773114, 0.92458993]])\n"
     ]
    }
   ],
   "source": [
    "x = x1.unsqueeze(1)\n",
    "y = x2.unsqueeze(0)\n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "cos_sim_func = paddle.nn.CosineSimilarity(axis=-1)\n",
    "result = cos_sim_func(x, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[5], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
       "       [0.52750373, 0.83689672, 0.75037485, 1.        , 0.92458993])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddle.diag(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[4], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0.87143707, 0.80905795, 0.79628360, 0.70043772])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeffye/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cos_sim_func = paddle.nn.CosineSimilarity(axis=0)\n",
    "result = cos_sim_func(x1, x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[5], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0.52750373, 0.83689672, 0.75037485, 1.        , 0.92458993])\n"
     ]
    }
   ],
   "source": [
    "cos_sim_func = paddle.nn.CosineSimilarity(axis=1)\n",
    "result = cos_sim_func(x1, x2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0.87143707])\n"
     ]
    }
   ],
   "source": [
    "cos_sim_func = paddle.nn.CosineSimilarity(axis=0)\n",
    "result = cos_sim_func(x1[:, 0], x2[:, 0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1], dtype=float32, place=Place(gpu:0), stop_gradient=True,\n",
      "       [0.52750373])\n"
     ]
    }
   ],
   "source": [
    "cos_sim_func = paddle.nn.CosineSimilarity(axis=0)\n",
    "result = cos_sim_func(x1[0, :], x2[0, :])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paddle Train\n",
    "\n",
    "### fp16 training\n",
    "\n",
    "* \n",
    "\n",
    "### Gradient Accumulation in dygraph graph mode\n",
    "* <https://www.paddlepaddle.org.cn/documentation/docs/en/guides/performance_improving/amp_en.html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = paddle.nn.MSELoss() # Define loss calculation function\n",
    "model = SimpleNet(input_size, output_size)  # Define SimpleNet model\n",
    "optimizer = paddle.optimizer.SGD(learning_rate=0.0001, parameters=model.parameters())  # Define SGD optimizer\n",
    "\n",
    "accumulate_batchs_num = 10 # the batch numbers of gradients accumulation\n",
    "\n",
    "# define GradScaler\n",
    "scaler = paddle.amp.GradScaler(init_loss_scaling=1024)\n",
    "\n",
    "train_time = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, label) in enumerate(loader):\n",
    "        start_time = time.time() # get start time\n",
    "        label._to(place) # Copy label to GPU\n",
    "         # create AMP context environment\n",
    "        with paddle.amp.auto_cast(level='O1'):\n",
    "            output = model(data)\n",
    "            loss = mse(output, label)\n",
    "        # use GradScaler complete the loss scaling\n",
    "        scaled = scaler.scale(loss)\n",
    "        scaled.backward()\n",
    "\n",
    "        #  when the accumulated batch is accumulate_batchs_num, update the model parameters\n",
    "        if (i + 1) % accumulate_batchs_num == 0:\n",
    "            # update parameters\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.clear_grad(set_to_zero=False)\n",
    "        # record training loss and training time\n",
    "        train_loss = loss.numpy()\n",
    "        train_time += time.time() - start_time\n",
    "\n",
    "print(\"loss:\", train_loss)\n",
    "print(\"Time consuming using AMP-O1 mode:{:.3f} sec\".format(train_time/(epochs*nums_batch)))\n",
    "# loss: [0.6602017]\n",
    "# Time consuming using AMP-O1 mode:0.113 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use high level API with AMP usage\n",
    "* https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/quick_start/high_level_api/high_level_api.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.vision.transforms as T\n",
    "\n",
    "\n",
    "def run_example_code():\n",
    "    device = paddle.set_device('gpu')\n",
    "    # Using high level API to define neural network\n",
    "    net = nn.Sequential(nn.Flatten(1), nn.Linear(\n",
    "        784, 200), nn.Tanh(), nn.Linear(200, 10))\n",
    "    model = paddle.Model(net)\n",
    "    # Define optimizer\n",
    "    optim = paddle.optimizer.SGD(\n",
    "        learning_rate=1e-3, parameters=model.parameters())\n",
    "    # Initialize neural network\n",
    "    amp_configs = {\n",
    "        \"level\": \"O1\",                    # Level corresponds to amp mode: O1, O2\n",
    "        # Customize the white list and support custom_black_list\n",
    "        \"custom_white_list\": {'conv2d'},\n",
    "        \"use_dynamic_loss_scaling\": True  # Dynamic loss_scaling\n",
    "    }\n",
    "    model.prepare(optim,\n",
    "                  paddle.nn.CrossEntropyLoss(),\n",
    "                  paddle.metric.Accuracy(),\n",
    "                  amp_configs=amp_configs)\n",
    "    # prepare data\n",
    "    transform = T.Compose([T.Transpose(), T.Normalize([127.5], [127.5])])\n",
    "    data = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "    # use AMP training\n",
    "    model.fit(data, epochs=2, batch_size=32, verbose=1)\n",
    "\n",
    "\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    run_example_code()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaddleHub\n",
    "\n",
    "* https://www.paddlepaddle.org.cn/hublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=/home/$USER/anaconda3/lib:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Can not import paddle core while this file exists: /home/jeffye/anaconda3/lib/python3.8/site-packages/paddle/fluid/libpaddle.so\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libpython3.8.so.1.0: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7a947b2a4a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m x_data = np.array([[[0, 1, 0],\n\u001b[1;32m      5\u001b[0m                     [ 1,  0, 1]]]).astype(\"float32\")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonkey_patch_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonkey_patch_math_varbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/framework/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# TODO: import framework api under this directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_default_dtype\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/framework/random.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# TODO: define random api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/fluid/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# import all class inside framework into fluid module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# import all class inside executor into fluid module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframework_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfluid_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/fluid/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;34m\"Error: Your machine doesn't support AVX, but the installed PaddlePaddle is avx core, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \"you should reinstall paddlepaddle with no-avx core.\\n\")\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/paddle/fluid/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibpaddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavx_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlibpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiled_with_avx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         sys.stderr.write(\n",
      "\u001b[0;31mImportError\u001b[0m: libpython3.8.so.1.0: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[[0, 1, 0],\n",
    "                    [ 1,  0, 1]]]).astype(\"float32\")\n",
    "print(x_data.shape)\n",
    "paddle.disable_static()\n",
    "x = paddle.to_tensor(x_data, stop_gradient=False)\n",
    "output = paddle.nn.functional.label_smooth(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d76abebb651b803d7523773c2538185af67bbe68e12b1f9d8b8e0e281792ff9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
