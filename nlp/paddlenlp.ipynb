{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleNlp\n",
    "\n",
    "## PaddlePaddle install \n",
    "\n",
    "* https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html\n",
    "\n",
    "## PaddleNlp docs.\n",
    "\n",
    "* https://paddlenlp.readthedocs.io/zh/latest -- 文档\n",
    "\n",
    "## source code \n",
    "\n",
    "### all supported transformer tokenizer\n",
    "\n",
    "* paddlenlp/transformers/auto/tokenizer.py\n",
    "* paddlenlp/transformers/ernie/tokenizer.py  # ernie相关的\n",
    "\n",
    "### transformer model configs\n",
    "\n",
    "* paddlenlp/transformers/ernie/modeling.py\n",
    "\n",
    "### transformer model zoom, and supported language.\n",
    "\n",
    "* https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html#transformer  -- bert  有Portuguese 支持\n",
    "* https://paddlenlp.readthedocs.io/zh/latest/model_zoo/transformers/GPT/contents.html -- GPT 有Portuguese 支持"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaddleNlp 数据集、模型下载到默认路径\n",
    "\n",
    "* A: 内置的数据集、模型默认会下载到$HOME/.paddlenlp/下，通过配置环境变量可下载到指定路径：\n",
    "\n",
    "    *（1）Linux下，设置 export PPNLP_HOME=\"xxxx\"，注意不要设置带有中文字符的路径。\n",
    "\n",
    "    *（2）Windows下，同样配置环境变量 PPNLP_HOME 到其他非中文字符路径，重启即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer 返回结果含义\n",
    "\n",
    "* model_outputs.py 中 BaseModelOutputWithPoolingAndCrossAttentions 有详细说明\n",
    "    * https://huggingface.co/transformers/v3.0.2/model_doc/bert.html 解释, BertModel\n",
    "* modeling.py 中有 ErnieForSequenceClassification， ErnieForQuestionAnswering， ErnieForTokenClassification， ErnieLMPredictionHead， ErnieForMultipleChoice， ErnieForMaskedLM\n",
    "\n",
    "### Transformers pytorch return\n",
    "\n",
    "* last_hidden_state (torch.FloatTensor of shape (batch_size, sequence_length, hidden_size)):\n",
    "    * Sequence of hidden-states at the output of the last layer of the model.\n",
    "* pooler_output (torch.FloatTensor: of shape (batch_size, hidden_size)):\n",
    "    * Last layer hidden-state of the first token of the sequence (classification token) further processed by a Linear layer and a Tanh activation function. The Linear layer weights are trained from the next sentence prediction (classification) objective during pre-training.\n",
    "\n",
    "    * This output is usually not a good summary of the semantic content of the input, you’re often better with averaging or pooling the sequence of hidden-states for the whole input sequence.\n",
    "\n",
    "* hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True):\n",
    "    * Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "    * Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "\n",
    "* attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True):\n",
    "    * Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "    * Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
    "\n",
    "### ernie 超详细中文预训练模型ERNIE使用指南\n",
    "* https://aistudio.baidu.com/paddle/forum/topic/show/954092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-09-29 21:10:06,975] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\u001b[0m\n",
      "\u001b[32m[2022-09-29 21:10:06,983] [    INFO]\u001b[0m - Already cached /mnt/d/dataset/nlp/paddle/.paddlenlp/models/ernie-3.0-medium-zh/ernie_3.0_medium_zh_vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-09-29 21:10:07,052] [    INFO]\u001b[0m - tokenizer config file saved in /mnt/d/dataset/nlp/paddle/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-09-29 21:10:07,061] [    INFO]\u001b[0m - Special tokens file saved in /mnt/d/dataset/nlp/paddle/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 11693, 1904, 5442, 10366, 36962, 10581, 36962, 1662, 10366, 36962, 37560, 9502, 12046, 2, 6368, 4604, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoModel, AutoTokenizer\n",
    "from paddlenlp.transformers import ErnieForTokenClassification, ErnieTokenizer\n",
    "\n",
    "import paddle\n",
    "\n",
    "model_name = 'ernie-3.0-medium-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = ErnieForTokenClassification.from_pretrained(model_name)\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(\"Welcome to use PaddlePaddle and PaddleNLP!\", \"hello world\")\n",
    "print(inputs)\n",
    "# inputs = {k:paddle.to_tensor([v]) for (k, v) in inputs.items()}\n",
    "# # logits = model(**inputs, return_dict=True, output_hidden_states=True, output_attentions=True)\n",
    "# logits = model(**inputs)\n",
    "# print(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 15, 768], dtype=float32, place=Place(gpu:0), stop_gradient=False,\n",
      "       [[[ 0.06013136,  0.08001949,  0.05949559, ...,  0.03834157,\n",
      "           0.16428161, -0.02553395],\n",
      "         [ 0.17710927,  1.07631350,  0.22704059, ..., -0.01483721,\n",
      "          -0.58641475, -0.37783957],\n",
      "         [ 0.63684541,  0.03024112,  0.39377603, ...,  0.12226901,\n",
      "           0.43927503,  1.50784373],\n",
      "         ...,\n",
      "         [ 1.05572450,  2.52401543, -0.73081750, ..., -0.19437474,\n",
      "           0.94409478,  1.50580680],\n",
      "         [-0.25393343,  0.31314465,  0.06259530, ..., -0.44231522,\n",
      "          -0.11833040, -0.35460761],\n",
      "         [ 0.34953618, -1.13955617,  0.45758203, ...,  0.39407942,\n",
      "           0.17412712, -0.47145003]]])\n"
     ]
    }
   ],
   "source": [
    "print(logits.hidden_states[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-08-10 15:14:33,981] [    INFO]\u001b[0m - Downloading tokenizer_config.json from https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/tokenizer_config.json\u001b[0m\n",
      "100%|██████████| 167/167 [00:00<00:00, 89.6kB/s]\n",
      "\u001b[32m[2022-08-10 15:14:34,215] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.bert.tokenizer.BertTokenizer'> to load 'neuralmind/bert-base-portuguese-cased'.\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:34,217] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/vocab.txt and saved to /home/jeffye/.paddlenlp/models/neuralmind/bert-base-portuguese-cased\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:34,218] [    INFO]\u001b[0m - Downloading vocab.txt from https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/vocab.txt\u001b[0m\n",
      "100%|██████████| 205k/205k [00:00<00:00, 956kB/s] \n",
      "\u001b[32m[2022-08-10 15:14:34,699] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/added_tokens.json and saved to /home/jeffye/.paddlenlp/models/neuralmind/bert-base-portuguese-cased\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:34,700] [    INFO]\u001b[0m - Downloading added_tokens.json from https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/added_tokens.json\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:34,879] [    INFO]\u001b[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/special_tokens_map.json and saved to /home/jeffye/.paddlenlp/models/neuralmind/bert-base-portuguese-cased\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:34,881] [    INFO]\u001b[0m - Downloading special_tokens_map.json from https://bj.bcebos.com/paddlenlp/models/community/neuralmind/bert-base-portuguese-cased/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2022-08-10 15:14:35,067] [    INFO]\u001b[0m - Already cached /home/jeffye/.paddlenlp/models/neuralmind/bert-base-portuguese-cased/tokenizer_config.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tokenizer_pt = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "# del pretrained_model\n",
    "# pretrained_model = AutoModel.from_pretrained(\"pierreguillou/bert-base-cased-squad-v1.1-portuguese\")\n",
    "# del pretrained_model\n",
    "pretrained_model = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAC\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-09-17 21:39:07,334] [    INFO]\u001b[0m - Downloading model_state.pdparams from https://bj.bcebos.com/paddlenlp/taskflow/lexical_analysis/lac/model_state.pdparams\u001b[0m\n",
      "100%|██████████| 32.3M/32.3M [00:07<00:00, 4.46MB/s]\n",
      "\u001b[32m[2022-09-17 21:54:48,276] [    INFO]\u001b[0m - Downloading tag.dic from https://bj.bcebos.com/paddlenlp/taskflow/lexical_analysis/lac/tag.dic\u001b[0m\n",
      "100%|██████████| 425/425 [00:00<00:00, 897kB/s]\n",
      "\u001b[32m[2022-09-17 22:10:16,571] [    INFO]\u001b[0m - Downloading q2b.dic from https://bj.bcebos.com/paddlenlp/taskflow/lexical_analysis/lac/q2b.dic\u001b[0m\n",
      "100%|██████████| 44.1k/44.1k [00:00<00:00, 621kB/s]\n",
      "\u001b[32m[2022-09-17 22:10:16,924] [    INFO]\u001b[0m - Downloading word.dic from https://bj.bcebos.com/paddlenlp/taskflow/lexical_analysis/lac/word.dic\u001b[0m\n",
      "100%|██████████| 745k/745k [00:00<00:00, 2.26MB/s]\n",
      "\u001b[32m[2022-09-17 22:10:20,893] [    INFO]\u001b[0m - Converting to the inference model cost a little time.\u001b[0m\n",
      "\u001b[32m[2022-09-17 22:10:21,332] [    INFO]\u001b[0m - The inference model save in the path:/mnt/d/dataset/nlp/paddle/.paddlenlp/taskflow/lac/static/inference\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from paddlenlp import Taskflow\n",
    "\n",
    "lac = Taskflow(\"lexical_analysis\")\n",
    "lac(\"LAC是个优秀的分词工具\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d76abebb651b803d7523773c2538185af67bbe68e12b1f9d8b8e0e281792ff9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
