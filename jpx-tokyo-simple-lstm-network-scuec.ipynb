{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Introduction\n",
    "The competition is to predict the highest future returns for stocks that are actually traded on the Japan Exchange Group, Inc.\n",
    "In this notebook, we will work with `jpx_tokyo_market_prediction`, which is unfamiliar to Kaggle beginners, and how to extract the relevant data in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "*  [Explanation of data](#Explanation-of-data)\n",
    "*  [jpx_tokyo_market_prediction](#jpx_tokyo_market_prediction)\n",
    "*  [Create models and submit data](#Create-models-and-submit-data)\n",
    "\n",
    "# TODO\n",
    "* add sharp ratio metrics for evaluation\n",
    "* improve prediction with dataframe operation\n",
    "* use qlib data preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch gpu check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.2+cu111\n",
      "11.1\n",
      "is_cuda_available: True\n",
      "gpu count: 2\n",
      "cuda:0 capability: (8, 6)\n",
      "cuda:0 name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# check gpu env with torch\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)  # 查看torch当前版本号\n",
    "\n",
    "print(torch.version.cuda)  # 编译当前版本的torch使用的cuda版本号\n",
    "\n",
    "print(\"is_cuda_available:\", torch.cuda.is_available())  # 查看当前cuda是否可用于当前版本的Torch，如果输出\n",
    "print('gpu count:', torch.cuda.device_count())\n",
    "# 查看指定GPU的容量、名称\n",
    "device = \"cuda:0\"\n",
    "\n",
    "print(f\"{device} capability:\", torch.cuda.get_device_capability(device))\n",
    "\n",
    "print(f\"{device} name:\", torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of data\n",
    "## Loading Modules\n",
    "First, load the required modules.  \n",
    "In this case, we will use pandas to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data\n",
    "Read *`stock_price.csv`* using `read_csv` in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stock_price_df = pd.read_csv(\"/mnt/d/dataset/quant/kaggle22/train_files/stock_prices.csv\")\n",
    "test_stock_price_df = pd.read_csv(\"/mnt/d/dataset/quant/kaggle22/supplemental_files/stock_prices.csv\")\n",
    "\n",
    "# stock_price_df = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction//train_files/stock_prices.csv\")\n",
    "# test_stock_price_df = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.038994</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.047764</td>\n",
       "      <td>0.041374</td>\n",
       "      <td>-0.169192</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1332</td>\n",
       "      <td>-0.566509</td>\n",
       "      <td>-0.566547</td>\n",
       "      <td>-0.565510</td>\n",
       "      <td>-0.565637</td>\n",
       "      <td>0.537161</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.155286</td>\n",
       "      <td>0.161205</td>\n",
       "      <td>0.163796</td>\n",
       "      <td>0.172227</td>\n",
       "      <td>-0.108081</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1376</td>\n",
       "      <td>-0.303174</td>\n",
       "      <td>-0.297439</td>\n",
       "      <td>-0.297504</td>\n",
       "      <td>-0.291909</td>\n",
       "      <td>-0.174323</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.188832</td>\n",
       "      <td>0.199886</td>\n",
       "      <td>0.200587</td>\n",
       "      <td>0.205779</td>\n",
       "      <td>-0.138713</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332526</th>\n",
       "      <td>20211203_9990</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9990</td>\n",
       "      <td>-0.581605</td>\n",
       "      <td>-0.579809</td>\n",
       "      <td>-0.579661</td>\n",
       "      <td>-0.577660</td>\n",
       "      <td>-0.165925</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.034816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332527</th>\n",
       "      <td>20211203_9991</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9991</td>\n",
       "      <td>-0.506685</td>\n",
       "      <td>-0.506316</td>\n",
       "      <td>-0.503532</td>\n",
       "      <td>-0.503287</td>\n",
       "      <td>-0.168043</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.025478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332528</th>\n",
       "      <td>20211203_9993</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9993</td>\n",
       "      <td>-0.252855</td>\n",
       "      <td>-0.258758</td>\n",
       "      <td>-0.259298</td>\n",
       "      <td>-0.265347</td>\n",
       "      <td>-0.175369</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332529</th>\n",
       "      <td>20211203_9994</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9994</td>\n",
       "      <td>-0.057730</td>\n",
       "      <td>-0.063696</td>\n",
       "      <td>-0.051288</td>\n",
       "      <td>-0.057325</td>\n",
       "      <td>-0.175548</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.009098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332530</th>\n",
       "      <td>20211203_9997</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9997</td>\n",
       "      <td>-0.532404</td>\n",
       "      <td>-0.529248</td>\n",
       "      <td>-0.530701</td>\n",
       "      <td>-0.530687</td>\n",
       "      <td>-0.079925</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.018414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2324923 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowId       Date  SecuritiesCode      Open      High  \\\n",
       "0        20170104_1301 2017-01-04            1301  0.038994  0.035493   \n",
       "1        20170104_1332 2017-01-04            1332 -0.566509 -0.566547   \n",
       "2        20170104_1333 2017-01-04            1333  0.155286  0.161205   \n",
       "3        20170104_1376 2017-01-04            1376 -0.303174 -0.297439   \n",
       "4        20170104_1377 2017-01-04            1377  0.188832  0.199886   \n",
       "...                ...        ...             ...       ...       ...   \n",
       "2332526  20211203_9990 2021-12-03            9990 -0.581605 -0.579809   \n",
       "2332527  20211203_9991 2021-12-03            9991 -0.506685 -0.506316   \n",
       "2332528  20211203_9993 2021-12-03            9993 -0.252855 -0.258758   \n",
       "2332529  20211203_9994 2021-12-03            9994 -0.057730 -0.063696   \n",
       "2332530  20211203_9997 2021-12-03            9997 -0.532404 -0.529248   \n",
       "\n",
       "              Low     Close    Volume  AdjustmentFactor  ExpectedDividend  \\\n",
       "0        0.047764  0.041374 -0.169192         -0.007493         -0.053484   \n",
       "1       -0.565510 -0.565637  0.537161         -0.007493         -0.053484   \n",
       "2        0.163796  0.172227 -0.108081         -0.007493         -0.053484   \n",
       "3       -0.297504 -0.291909 -0.174323         -0.007493         -0.053484   \n",
       "4        0.200587  0.205779 -0.138713         -0.007493         -0.053484   \n",
       "...           ...       ...       ...               ...               ...   \n",
       "2332526 -0.579661 -0.577660 -0.165925         -0.007493         -0.053484   \n",
       "2332527 -0.503532 -0.503287 -0.168043         -0.007493         -0.053484   \n",
       "2332528 -0.259298 -0.265347 -0.175369         -0.007493         -0.053484   \n",
       "2332529 -0.051288 -0.057325 -0.175548         -0.007493         -0.053484   \n",
       "2332530 -0.530701 -0.530687 -0.079925         -0.007493         -0.053484   \n",
       "\n",
       "         SupervisionFlag    Target  \n",
       "0              -0.025162  0.000730  \n",
       "1              -0.025162  0.012324  \n",
       "2              -0.025162  0.006154  \n",
       "3              -0.025162  0.011053  \n",
       "4              -0.025162  0.003026  \n",
       "...                  ...       ...  \n",
       "2332526        -0.025162  0.034816  \n",
       "2332527        -0.025162  0.025478  \n",
       "2332528        -0.025162 -0.004302  \n",
       "2332529        -0.025162  0.009098  \n",
       "2332530        -0.025162  0.018414  \n",
       "\n",
       "[2324923 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = preprocess(stock_price_df, stdsc, is_fit=True)\n",
    "test_df = preprocess(test_stock_price_df, stdsc, is_fit=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define metric: sharp rate and compute for the training data with known Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2, rank='Rank') -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): predicted results\n",
    "        portfolio_size (int): # of equities to buy/sell\n",
    "        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "    Returns:\n",
    "        (float): sharpe ratio\n",
    "    \"\"\"\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio, rank='Rank'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): predicted results\n",
    "            portfolio_size (int): # of equities to buy/sell\n",
    "            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "        Returns:\n",
    "            (float): spread return\n",
    "        \"\"\"\n",
    "        assert df[rank].min() == 0\n",
    "        assert df[rank].max() == len(df[rank]) - 1\n",
    "        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        purchase = (df.sort_values(by=rank)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by=rank, ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio, rank)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1994\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2331270</th>\n",
       "      <td>20211203_4699</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>4699</td>\n",
       "      <td>-0.127058</td>\n",
       "      <td>-0.123375</td>\n",
       "      <td>-0.125719</td>\n",
       "      <td>-0.121353</td>\n",
       "      <td>-0.172179</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>39.742988</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330587</th>\n",
       "      <td>20211203_1873</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1873</td>\n",
       "      <td>-0.629687</td>\n",
       "      <td>-0.628437</td>\n",
       "      <td>-0.628621</td>\n",
       "      <td>-0.626870</td>\n",
       "      <td>-0.155714</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.186782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331721</th>\n",
       "      <td>20211203_6779</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>6779</td>\n",
       "      <td>-0.289755</td>\n",
       "      <td>-0.288598</td>\n",
       "      <td>-0.303447</td>\n",
       "      <td>-0.293027</td>\n",
       "      <td>-0.044672</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.159624</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331997</th>\n",
       "      <td>20211203_7809</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>7809</td>\n",
       "      <td>0.968774</td>\n",
       "      <td>1.050865</td>\n",
       "      <td>0.925083</td>\n",
       "      <td>1.066947</td>\n",
       "      <td>-0.165388</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.136667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330836</th>\n",
       "      <td>20211203_3031</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>3031</td>\n",
       "      <td>-0.392350</td>\n",
       "      <td>-0.396075</td>\n",
       "      <td>-0.397971</td>\n",
       "      <td>-0.402351</td>\n",
       "      <td>0.244368</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>0.119069</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331784</th>\n",
       "      <td>20211203_6958</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>6958</td>\n",
       "      <td>-0.577970</td>\n",
       "      <td>-0.579809</td>\n",
       "      <td>-0.582491</td>\n",
       "      <td>-0.581575</td>\n",
       "      <td>-0.065910</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.058201</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332479</th>\n",
       "      <td>20211203_9790</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9790</td>\n",
       "      <td>0.343982</td>\n",
       "      <td>0.349084</td>\n",
       "      <td>0.356240</td>\n",
       "      <td>0.353967</td>\n",
       "      <td>-0.171285</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.084321</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330656</th>\n",
       "      <td>20211203_2158</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>2158</td>\n",
       "      <td>0.142707</td>\n",
       "      <td>0.170875</td>\n",
       "      <td>-0.055533</td>\n",
       "      <td>-0.064035</td>\n",
       "      <td>2.842232</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.091797</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331698</th>\n",
       "      <td>20211203_6718</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>6718</td>\n",
       "      <td>-0.122585</td>\n",
       "      <td>-0.114534</td>\n",
       "      <td>-0.121191</td>\n",
       "      <td>-0.111847</td>\n",
       "      <td>-0.164546</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.092211</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332506</th>\n",
       "      <td>20211203_9919</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>9919</td>\n",
       "      <td>-0.217352</td>\n",
       "      <td>-0.215933</td>\n",
       "      <td>-0.214866</td>\n",
       "      <td>-0.213901</td>\n",
       "      <td>-0.163117</td>\n",
       "      <td>-0.007493</td>\n",
       "      <td>-0.053484</td>\n",
       "      <td>-0.025162</td>\n",
       "      <td>-0.224215</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RowId       Date  SecuritiesCode      Open      High  \\\n",
       "2331270  20211203_4699 2021-12-03            4699 -0.127058 -0.123375   \n",
       "2330587  20211203_1873 2021-12-03            1873 -0.629687 -0.628437   \n",
       "2331721  20211203_6779 2021-12-03            6779 -0.289755 -0.288598   \n",
       "2331997  20211203_7809 2021-12-03            7809  0.968774  1.050865   \n",
       "2330836  20211203_3031 2021-12-03            3031 -0.392350 -0.396075   \n",
       "...                ...        ...             ...       ...       ...   \n",
       "2331784  20211203_6958 2021-12-03            6958 -0.577970 -0.579809   \n",
       "2332479  20211203_9790 2021-12-03            9790  0.343982  0.349084   \n",
       "2330656  20211203_2158 2021-12-03            2158  0.142707  0.170875   \n",
       "2331698  20211203_6718 2021-12-03            6718 -0.122585 -0.114534   \n",
       "2332506  20211203_9919 2021-12-03            9919 -0.217352 -0.215933   \n",
       "\n",
       "              Low     Close    Volume  AdjustmentFactor  ExpectedDividend  \\\n",
       "2331270 -0.125719 -0.121353 -0.172179         -0.007493         -0.053484   \n",
       "2330587 -0.628621 -0.626870 -0.155714         -0.007493         -0.053484   \n",
       "2331721 -0.303447 -0.293027 -0.044672         -0.007493         -0.053484   \n",
       "2331997  0.925083  1.066947 -0.165388         -0.007493         -0.053484   \n",
       "2330836 -0.397971 -0.402351  0.244368         -0.007493         -0.053484   \n",
       "...           ...       ...       ...               ...               ...   \n",
       "2331784 -0.582491 -0.581575 -0.065910         -0.007493         -0.053484   \n",
       "2332479  0.356240  0.353967 -0.171285         -0.007493         -0.053484   \n",
       "2330656 -0.055533 -0.064035  2.842232         -0.007493         -0.053484   \n",
       "2331698 -0.121191 -0.111847 -0.164546         -0.007493         -0.053484   \n",
       "2332506 -0.214866 -0.213901 -0.163117         -0.007493         -0.053484   \n",
       "\n",
       "         SupervisionFlag    Target  Rank  \n",
       "2331270        39.742988  0.187970     0  \n",
       "2330587        -0.025162  0.186782     1  \n",
       "2331721        -0.025162  0.159624     2  \n",
       "2331997        -0.025162  0.136667     3  \n",
       "2330836        -0.025162  0.119069     4  \n",
       "...                  ...       ...   ...  \n",
       "2331784        -0.025162 -0.058201  1990  \n",
       "2332479        -0.025162 -0.084321  1991  \n",
       "2330656        -0.025162 -0.091797  1992  \n",
       "2331698        -0.025162 -0.092211  1993  \n",
       "2332506        -0.025162 -0.224215  1994  \n",
       "\n",
       "[1995 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add rank according to Target for train\n",
    "\n",
    "train_df['Rank'] = train_df.groupby(\"Date\")['Target'].transform('rank', ascending=False, method=\"first\") - 1\n",
    "train_df['Rank'] = train_df['Rank'].astype(int)\n",
    "# print(train_df['Rank'].min())\n",
    "df_astock = train_df[train_df['Date'] == '2021-12-03']\n",
    "\n",
    "# make sure it's correct\n",
    "print(df_astock['Rank'].min(), df_astock['Rank'].max())\n",
    "df_astock.sort_values(by=['Target'], ascending=False)\n",
    "# sharp = calc_spread_return_sharpe(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "      <th>Close_shift1</th>\n",
       "      <th>Close_shift2</th>\n",
       "      <th>rate</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211206_1301</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.076114</td>\n",
       "      <td>0.068435</td>\n",
       "      <td>-0.258364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>-0.492081</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.855021</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20211206_1332</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1332</td>\n",
       "      <td>-0.491403</td>\n",
       "      <td>-0.491636</td>\n",
       "      <td>-0.490380</td>\n",
       "      <td>-0.492081</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.008993</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>3.803073</td>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20211206_1333</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1333</td>\n",
       "      <td>-0.074290</td>\n",
       "      <td>-0.076388</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.207317</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.009963</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>-0.312773</td>\n",
       "      <td>-0.087215</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20211206_1375</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1375</td>\n",
       "      <td>-0.341562</td>\n",
       "      <td>-0.343084</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>-0.226863</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>-0.312773</td>\n",
       "      <td>0.122321</td>\n",
       "      <td>-1.391088</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20211206_1376</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1376</td>\n",
       "      <td>-0.315962</td>\n",
       "      <td>-0.312213</td>\n",
       "      <td>-0.311399</td>\n",
       "      <td>-0.312773</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.122321</td>\n",
       "      <td>-0.186174</td>\n",
       "      <td>-2.522007</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111995</th>\n",
       "      <td>20220228_9990</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9990</td>\n",
       "      <td>-0.510427</td>\n",
       "      <td>-0.510437</td>\n",
       "      <td>-0.509208</td>\n",
       "      <td>-0.509259</td>\n",
       "      <td>-0.209630</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.013592</td>\n",
       "      <td>-0.437253</td>\n",
       "      <td>-0.254180</td>\n",
       "      <td>-0.418690</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111996</th>\n",
       "      <td>20220228_9991</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9991</td>\n",
       "      <td>-0.437150</td>\n",
       "      <td>-0.439178</td>\n",
       "      <td>-0.436519</td>\n",
       "      <td>-0.437253</td>\n",
       "      <td>-0.255179</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.020581</td>\n",
       "      <td>-0.254180</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>-0.893373</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111997</th>\n",
       "      <td>20220228_9993</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9993</td>\n",
       "      <td>-0.254663</td>\n",
       "      <td>-0.254186</td>\n",
       "      <td>-0.249197</td>\n",
       "      <td>-0.254180</td>\n",
       "      <td>-0.260502</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>-0.457961</td>\n",
       "      <td>15.897421</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111998</th>\n",
       "      <td>20220228_9994</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9994</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>-0.258320</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.002341</td>\n",
       "      <td>-0.457961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111999</th>\n",
       "      <td>20220228_9997</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9997</td>\n",
       "      <td>-0.458757</td>\n",
       "      <td>-0.459604</td>\n",
       "      <td>-0.457491</td>\n",
       "      <td>-0.457961</td>\n",
       "      <td>-0.136550</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.030014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111716 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                RowId       Date  SecuritiesCode      Open      High  \\\n",
       "0       20211206_1301 2021-12-06            1301  0.069915  0.061486   \n",
       "1       20211206_1332 2021-12-06            1332 -0.491403 -0.491636   \n",
       "2       20211206_1333 2021-12-06            1333 -0.074290 -0.076388   \n",
       "3       20211206_1375 2021-12-06            1375 -0.341562 -0.343084   \n",
       "4       20211206_1376 2021-12-06            1376 -0.315962 -0.312213   \n",
       "...               ...        ...             ...       ...       ...   \n",
       "111995  20220228_9990 2022-02-28            9990 -0.510427 -0.510437   \n",
       "111996  20220228_9991 2022-02-28            9991 -0.437150 -0.439178   \n",
       "111997  20220228_9993 2022-02-28            9993 -0.254663 -0.254186   \n",
       "111998  20220228_9994 2022-02-28            9994 -0.027317 -0.034608   \n",
       "111999  20220228_9997 2022-02-28            9997 -0.458757 -0.459604   \n",
       "\n",
       "             Low     Close    Volume  AdjustmentFactor  ExpectedDividend  \\\n",
       "0       0.076114  0.068435 -0.258364          0.010497         -0.039402   \n",
       "1      -0.490380 -0.492081  0.331465          0.010497         -0.039402   \n",
       "2      -0.068072 -0.071341 -0.207317          0.010497         -0.039402   \n",
       "3      -0.338807 -0.342657 -0.226863          0.010497         -0.039402   \n",
       "4      -0.311399 -0.312773 -0.259542          0.010497         -0.039402   \n",
       "...          ...       ...       ...               ...               ...   \n",
       "111995 -0.509208 -0.509259 -0.209630          0.010497         -0.039402   \n",
       "111996 -0.436519 -0.437253 -0.255179          0.010497         -0.039402   \n",
       "111997 -0.249197 -0.254180 -0.260502          0.010497         -0.039402   \n",
       "111998 -0.025173 -0.027102 -0.258320          0.010497         -0.039402   \n",
       "111999 -0.457491 -0.457961 -0.136550          0.010497         -0.039402   \n",
       "\n",
       "        SupervisionFlag    Target  Close_shift1  Close_shift2       rate  Rank  \n",
       "0              -0.05215 -0.003263     -0.492081     -0.071341  -0.855021  1389  \n",
       "1              -0.05215 -0.008993     -0.071341     -0.342657   3.803073  1664  \n",
       "2              -0.05215 -0.009963     -0.342657     -0.312773  -0.087215  1706  \n",
       "3              -0.05215 -0.015032     -0.312773      0.122321  -1.391088  1838  \n",
       "4              -0.05215  0.002867      0.122321     -0.186174  -2.522007   978  \n",
       "...                 ...       ...           ...           ...        ...   ...  \n",
       "111995         -0.05215 -0.013592     -0.437253     -0.254180  -0.418690   786  \n",
       "111996         -0.05215 -0.020581     -0.254180     -0.027102  -0.893373  1119  \n",
       "111997         -0.05215  0.005762     -0.027102     -0.457961  15.897421   136  \n",
       "111998         -0.05215 -0.002341     -0.457961           NaN   0.000000   330  \n",
       "111999         -0.05215 -0.030014           NaN           NaN   0.000000  1526  \n",
       "\n",
       "[111716 rows x 16 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpdf = test_df.copy()\n",
    "tmpdf[\"Close_shift1\"] = tmpdf[\"Close\"].shift(-1)\n",
    "tmpdf[\"Close_shift2\"] = tmpdf[\"Close\"].shift(-2)\n",
    "\n",
    "tmpdf[\"rate\"] = (tmpdf[\"Close_shift2\"] - tmpdf[\"Close_shift1\"]) / tmpdf[\"Close_shift1\"]\n",
    "tmpdf.fillna(value={'rate': 0.}, inplace=True)\n",
    "\n",
    "tmpdf['Rank'] = tmpdf.groupby(\"Date\")['Target'].transform('rank', ascending=False, method=\"first\") - 1\n",
    "tmpdf['Rank'] = tmpdf['Rank'].astype(int)\n",
    "tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211206_1301</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.076114</td>\n",
       "      <td>0.068435</td>\n",
       "      <td>-0.258364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.003263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20211206_1332</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1332</td>\n",
       "      <td>-0.491403</td>\n",
       "      <td>-0.491636</td>\n",
       "      <td>-0.490380</td>\n",
       "      <td>-0.492081</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.008993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20211206_1333</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1333</td>\n",
       "      <td>-0.074290</td>\n",
       "      <td>-0.076388</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.207317</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.009963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20211206_1375</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1375</td>\n",
       "      <td>-0.341562</td>\n",
       "      <td>-0.343084</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>-0.226863</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20211206_1376</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1376</td>\n",
       "      <td>-0.315962</td>\n",
       "      <td>-0.312213</td>\n",
       "      <td>-0.311399</td>\n",
       "      <td>-0.312773</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111995</th>\n",
       "      <td>20220228_9990</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9990</td>\n",
       "      <td>-0.510427</td>\n",
       "      <td>-0.510437</td>\n",
       "      <td>-0.509208</td>\n",
       "      <td>-0.509259</td>\n",
       "      <td>-0.209630</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.013592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111996</th>\n",
       "      <td>20220228_9991</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9991</td>\n",
       "      <td>-0.437150</td>\n",
       "      <td>-0.439178</td>\n",
       "      <td>-0.436519</td>\n",
       "      <td>-0.437253</td>\n",
       "      <td>-0.255179</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.020581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111997</th>\n",
       "      <td>20220228_9993</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9993</td>\n",
       "      <td>-0.254663</td>\n",
       "      <td>-0.254186</td>\n",
       "      <td>-0.249197</td>\n",
       "      <td>-0.254180</td>\n",
       "      <td>-0.260502</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.005762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111998</th>\n",
       "      <td>20220228_9994</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9994</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>-0.027102</td>\n",
       "      <td>-0.258320</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111999</th>\n",
       "      <td>20220228_9997</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>9997</td>\n",
       "      <td>-0.458757</td>\n",
       "      <td>-0.459604</td>\n",
       "      <td>-0.457491</td>\n",
       "      <td>-0.457961</td>\n",
       "      <td>-0.136550</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.030014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111716 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                RowId       Date  SecuritiesCode      Open      High  \\\n",
       "0       20211206_1301 2021-12-06            1301  0.069915  0.061486   \n",
       "1       20211206_1332 2021-12-06            1332 -0.491403 -0.491636   \n",
       "2       20211206_1333 2021-12-06            1333 -0.074290 -0.076388   \n",
       "3       20211206_1375 2021-12-06            1375 -0.341562 -0.343084   \n",
       "4       20211206_1376 2021-12-06            1376 -0.315962 -0.312213   \n",
       "...               ...        ...             ...       ...       ...   \n",
       "111995  20220228_9990 2022-02-28            9990 -0.510427 -0.510437   \n",
       "111996  20220228_9991 2022-02-28            9991 -0.437150 -0.439178   \n",
       "111997  20220228_9993 2022-02-28            9993 -0.254663 -0.254186   \n",
       "111998  20220228_9994 2022-02-28            9994 -0.027317 -0.034608   \n",
       "111999  20220228_9997 2022-02-28            9997 -0.458757 -0.459604   \n",
       "\n",
       "             Low     Close    Volume  AdjustmentFactor  ExpectedDividend  \\\n",
       "0       0.076114  0.068435 -0.258364          0.010497         -0.039402   \n",
       "1      -0.490380 -0.492081  0.331465          0.010497         -0.039402   \n",
       "2      -0.068072 -0.071341 -0.207317          0.010497         -0.039402   \n",
       "3      -0.338807 -0.342657 -0.226863          0.010497         -0.039402   \n",
       "4      -0.311399 -0.312773 -0.259542          0.010497         -0.039402   \n",
       "...          ...       ...       ...               ...               ...   \n",
       "111995 -0.509208 -0.509259 -0.209630          0.010497         -0.039402   \n",
       "111996 -0.436519 -0.437253 -0.255179          0.010497         -0.039402   \n",
       "111997 -0.249197 -0.254180 -0.260502          0.010497         -0.039402   \n",
       "111998 -0.025173 -0.027102 -0.258320          0.010497         -0.039402   \n",
       "111999 -0.457491 -0.457961 -0.136550          0.010497         -0.039402   \n",
       "\n",
       "        SupervisionFlag    Target  \n",
       "0              -0.05215 -0.003263  \n",
       "1              -0.05215 -0.008993  \n",
       "2              -0.05215 -0.009963  \n",
       "3              -0.05215 -0.015032  \n",
       "4              -0.05215  0.002867  \n",
       "...                 ...       ...  \n",
       "111995         -0.05215 -0.013592  \n",
       "111996         -0.05215 -0.020581  \n",
       "111997         -0.05215  0.005762  \n",
       "111998         -0.05215 -0.002341  \n",
       "111999         -0.05215 -0.030014  \n",
       "\n",
       "[111716 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=4.147729138076841, test=5.430028145273522\n"
     ]
    }
   ],
   "source": [
    "sharp_train = calc_spread_return_sharpe(train_df)\n",
    "sharp_test = calc_spread_return_sharpe(tmpdf)\n",
    "print(f\"train={sharp_train}, test={sharp_test}\")\n",
    "\n",
    "train_df.drop(['Rank'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the form of this data (nrows ,columns) and the contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contained in `stock_price.csv` was as follows.  \n",
    "*  `SecuritiesCode` ... Securities Code (number assigned to each stock)\n",
    "*  `Open` ... Opening price (price per share at the beginning of the day (9:00 am))\n",
    "*  `High` ... High ... the highest price of the day\n",
    "*  `Low` ... Low price\n",
    "*  `Colse` ... Closing price\n",
    "*  `Volume` ... Volume (number of shares traded in a day)\n",
    "*  `AdjustmentFactor` ... Used to calculate the theoretical stock price and volume at the time of a reverse stock split or reverse stock split\n",
    "*  `ExpectedDividend` ... Expected dividend on ex-rights date\n",
    "*  `SupercisionFlag` ... Flag for supervised issues and delisted issues\n",
    "*  `Target` ... Percentage change in adjusted closing price (from one day to the next)  \n",
    "  \n",
    "Although many other data are available for this competition, we will implement this using only the information in `stock_price.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jpx_tokyo_market_prediction\n",
    "Next, we will check the usage of the API named jpx_tokyo_market_prediction.  \n",
    "First, import it as you would any other module.  \n",
    "Since jpx_tokyo_market_prediction can only be executed once, we will write the image in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "```python\n",
    "import jpx_tokyo_market_prediction\n",
    "env = jpx_tokyo_market_prediction.make_env()\n",
    "iter_test = env.iter_test()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment was created by executing *`make_env()`* and the object was created by executing *`iter_test()`*.\n",
    "As shown below, looking at the type, iter_test is a generator, so we can confirm that it is an object that can be called one by one with a for statement.  \n",
    "***\n",
    "```python\n",
    "print(type(iter_test))\n",
    "```\n",
    "[出力]  \n",
    "```\n",
    "<class 'generator'>\n",
    "```\n",
    "By turning a for statement, check the operation as follows.\n",
    "***\n",
    "```python\n",
    "count = 0\n",
    "for (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n",
    "    print(prices.head())\n",
    "    env.predict(sample_prediction)\n",
    "    count += 1\n",
    "    break\n",
    "```\n",
    "[出力]\n",
    "```\n",
    "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
    "         Date          RowId  SecuritiesCode    Open    High     Low   Close  \\\n",
    "0  2021-12-06  20211206_1301            1301  2982.0  2982.0  2965.0  2971.0   \n",
    "1  2021-12-06  20211206_1332            1332   592.0   599.0   588.0   589.0   \n",
    "2  2021-12-06  20211206_1333            1333  2368.0  2388.0  2360.0  2377.0   \n",
    "3  2021-12-06  20211206_1375            1375  1230.0  1239.0  1224.0  1224.0   \n",
    "4  2021-12-06  20211206_1376            1376  1339.0  1372.0  1339.0  1351.0   \n",
    "\n",
    "    Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \n",
    "0     8900               1.0               NaN            False  \n",
    "1  1360800               1.0               NaN            False  \n",
    "2   125900               1.0               NaN            False  \n",
    "3    81100               1.0               NaN            False  \n",
    "4     6200               1.0               NaN            False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of each variable are as follows.  \n",
    "*  `price` ... Data for each stock on the target day, the same as the information in stock_price.csv without Target.　　\n",
    "*  `options` ... Same information as options.csv for the target date.\n",
    "*  `finacials` ... Same information as finacials.csv for the target date.\n",
    "*  `trades` ... Same information as trades.csv of the target date\n",
    "*  `secondary_prices` ... Same information as secondary_stock_price.csv without Target for the target date.\n",
    "*  `sample_prediction` ... Data from sample_prediction.csv for the target date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if we call the 2000 stocks of the target date one day at a time using *`jpx_tokyo_market_prediction`*, forecast them with the model we created, and then create the submitted data with env.predict, we can produce a score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and submit data\n",
    "Here, we will create a simple training model using stock_price.csv and implement it up to submission.\n",
    "## Create Model(LSTM)\n",
    "We use a model called LSTM (Long Short Term Memory).  \n",
    "LSTM is one of the RNNs used for series data and is a model that can learn long-term dependencies.  \n",
    "We will implement LSTM using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d_feat=6, hidden_size=64, num_layers=2, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=d_feat,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.d_feat = d_feat\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, F*T]\n",
    "        # x = x.reshape(len(x), self.d_feat, -1)  # [N, F, T]\n",
    "        # x = x.permute(0, 2, 1)  # [N, T, F]\n",
    "        out, _ = self.rnn(x)\n",
    "        \n",
    "        return self.fc_out(out[:, -1, :]).squeeze(dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_price_df['ExpectedDividend'] = stock_price_df['ExpectedDividend'].fillna(0)\n",
    "# stock_price_df['SupervisionFlag'] = stock_price_df['SupervisionFlag'].map({True: 1, False: 0})\n",
    "# stock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'])\n",
    "# stock_price_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them contained missing values, so they were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_price_df = stock_price_df.dropna(how='any')\n",
    "# # Confirmation of missing information\n",
    "# stock_price_df_na = (stock_price_df.isnull().sum() / len(stock_price_df)) * 100\n",
    "# stock_price_df_na = stock_price_df_na.drop(stock_price_df_na[stock_price_df_na == 0].index).sort_values(ascending=False)[:30]\n",
    "# missing_data = pd.DataFrame({'Missing Ratio' :stock_price_df_na})\n",
    "# missing_data.head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据预处理是否应该把所有股票放在一起？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stdscStandardize the features (other than RowId, Date, and SecuritiesCode) to be used in this project using sklearn's StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# stdsc = StandardScaler()\n",
    "# columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag']\n",
    "# stock_price_df[columns] = stdsc.fit_transform(stock_price_df[columns])\n",
    "# stock_price_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store data for each issue in dictionary form and store it in such a way that it can be recalled for each issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = {}\n",
    "for sc in train_df['SecuritiesCode'].unique():\n",
    "    dataset_dict[str(sc)] = train_df[train_df['SecuritiesCode'] == sc].values[:, 3:].astype(np.float32)\n",
    "print(dataset_dict['1301'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pytorch dataloader to recall data for each mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, sequence_num=31, y=None, mode='train'):\n",
    "        self.data = X\n",
    "        self.teacher = y\n",
    "        self.sequence_num = sequence_num\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.teacher)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        if self.mode == 'train':\n",
    "            out_label = self.teacher[idx[-1]]\n",
    "            return out_data, out_label\n",
    "        else:\n",
    "            return out_data\n",
    "\n",
    "        \n",
    "def create_dataloader(dataset, dataset_num, sequence_num=31, input_size=8, batch_size=32, shuffle=False):\n",
    "    sampler = np.array([list(range(i, i+sequence_num)) for i in range(dataset_num-sequence_num+1)])\n",
    "    if shuffle is True:\n",
    "        np.random.shuffle(sampler)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size, sampler=sampler)\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20211206_1301</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1301</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>0.061486</td>\n",
       "      <td>0.076114</td>\n",
       "      <td>0.068435</td>\n",
       "      <td>-0.258364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.003263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20211206_1332</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1332</td>\n",
       "      <td>-0.491403</td>\n",
       "      <td>-0.491636</td>\n",
       "      <td>-0.490380</td>\n",
       "      <td>-0.492081</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.008993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20211206_1333</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1333</td>\n",
       "      <td>-0.074290</td>\n",
       "      <td>-0.076388</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>-0.071341</td>\n",
       "      <td>-0.207317</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.009963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20211206_1375</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1375</td>\n",
       "      <td>-0.341562</td>\n",
       "      <td>-0.343084</td>\n",
       "      <td>-0.338807</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>-0.226863</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.015032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20211206_1376</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>1376</td>\n",
       "      <td>-0.315962</td>\n",
       "      <td>-0.312213</td>\n",
       "      <td>-0.311399</td>\n",
       "      <td>-0.312773</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>20211206_9990</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>9990</td>\n",
       "      <td>-0.506434</td>\n",
       "      <td>-0.507419</td>\n",
       "      <td>-0.507539</td>\n",
       "      <td>-0.509024</td>\n",
       "      <td>-0.233757</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.009346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>20211206_9991</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>9991</td>\n",
       "      <td>-0.443491</td>\n",
       "      <td>-0.444981</td>\n",
       "      <td>-0.443430</td>\n",
       "      <td>-0.445960</td>\n",
       "      <td>-0.249551</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>20211206_9993</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>9993</td>\n",
       "      <td>-0.244094</td>\n",
       "      <td>-0.246990</td>\n",
       "      <td>-0.242762</td>\n",
       "      <td>-0.247826</td>\n",
       "      <td>-0.259542</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.011728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>20211206_9994</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>9994</td>\n",
       "      <td>-0.068183</td>\n",
       "      <td>-0.065943</td>\n",
       "      <td>-0.060207</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>-0.258844</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>-0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>20211206_9997</td>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>9997</td>\n",
       "      <td>-0.465568</td>\n",
       "      <td>-0.464246</td>\n",
       "      <td>-0.464879</td>\n",
       "      <td>-0.464549</td>\n",
       "      <td>-0.138339</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.039402</td>\n",
       "      <td>-0.05215</td>\n",
       "      <td>0.019471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RowId       Date  SecuritiesCode      Open      High       Low  \\\n",
       "0     20211206_1301 2021-12-06            1301  0.069915  0.061486  0.076114   \n",
       "1     20211206_1332 2021-12-06            1332 -0.491403 -0.491636 -0.490380   \n",
       "2     20211206_1333 2021-12-06            1333 -0.074290 -0.076388 -0.068072   \n",
       "3     20211206_1375 2021-12-06            1375 -0.341562 -0.343084 -0.338807   \n",
       "4     20211206_1376 2021-12-06            1376 -0.315962 -0.312213 -0.311399   \n",
       "...             ...        ...             ...       ...       ...       ...   \n",
       "1995  20211206_9990 2021-12-06            9990 -0.506434 -0.507419 -0.507539   \n",
       "1996  20211206_9991 2021-12-06            9991 -0.443491 -0.444981 -0.443430   \n",
       "1997  20211206_9993 2021-12-06            9993 -0.244094 -0.246990 -0.242762   \n",
       "1998  20211206_9994 2021-12-06            9994 -0.068183 -0.065943 -0.060207   \n",
       "1999  20211206_9997 2021-12-06            9997 -0.465568 -0.464246 -0.464879   \n",
       "\n",
       "         Close    Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "0     0.068435 -0.258364          0.010497         -0.039402         -0.05215   \n",
       "1    -0.492081  0.331465          0.010497         -0.039402         -0.05215   \n",
       "2    -0.071341 -0.207317          0.010497         -0.039402         -0.05215   \n",
       "3    -0.342657 -0.226863          0.010497         -0.039402         -0.05215   \n",
       "4    -0.312773 -0.259542          0.010497         -0.039402         -0.05215   \n",
       "...        ...       ...               ...               ...              ...   \n",
       "1995 -0.509024 -0.233757          0.010497         -0.039402         -0.05215   \n",
       "1996 -0.445960 -0.249551          0.010497         -0.039402         -0.05215   \n",
       "1997 -0.247826 -0.259542          0.010497         -0.039402         -0.05215   \n",
       "1998 -0.061693 -0.258844          0.010497         -0.039402         -0.05215   \n",
       "1999 -0.464549 -0.138339          0.010497         -0.039402         -0.05215   \n",
       "\n",
       "        Target  \n",
       "0    -0.003263  \n",
       "1    -0.008993  \n",
       "2    -0.009963  \n",
       "3    -0.015032  \n",
       "4     0.002867  \n",
       "...        ...  \n",
       "1995  0.009346  \n",
       "1996  0.001242  \n",
       "1997  0.011728  \n",
       "1998 -0.001230  \n",
       "1999  0.019471  \n",
       "\n",
       "[1994 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['Date'] == \"2021-12-06\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig\n",
    "For each stock, LSTM training is conducted by repeatedly creating a data set and training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the learning status, check the phenomenon of the loss function.  \n",
    "　→Can be learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with training, random train_loss=0.000734238720120087, train_sharp=0.04209109962156693, eval_loss=0.001237477747054072, eval_sharp=0.05985383647992399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▉                                                                                                                                                                                                  | 1/50 [02:32<2:04:40, 152.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, run_time=73.89934062957764, train loss=0.0005624992571379237, eval_loss=0.0007073952983773779, eval_sharp=-0.09803753233479665\n",
      "\t train_loss=0.000558936436171065, train_sharp=0.018433095002756333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███████▉                                                                                                                                                                                              | 2/50 [05:02<2:00:58, 151.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, run_time=73.82773327827454, train loss=0.0005583647607467051, eval_loss=0.0007490831503673689, eval_sharp=0.05367736800822311\n",
      "\t train_loss=0.0005574382619060263, train_sharp=0.034508626596503555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███████████▉                                                                                                                                                                                          | 3/50 [07:33<1:58:12, 150.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, run_time=74.11204242706299, train loss=0.0005582176210895261, eval_loss=0.0007582023081340594, eval_sharp=-0.10385927765648957\n",
      "\t train_loss=0.0005581024070237821, train_sharp=0.015686140776172627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████████▊                                                                                                                                                                                      | 4/50 [10:03<1:55:24, 150.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, run_time=73.75530123710632, train loss=0.0005577685873990196, eval_loss=0.0007184226087701973, eval_sharp=0.010605269355142385\n",
      "\t train_loss=0.0005576910579129504, train_sharp=0.026116069262780768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████████████▊                                                                                                                                                                                  | 5/50 [12:34<1:52:57, 150.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, run_time=74.34958052635193, train loss=0.0005578871784581346, eval_loss=0.0007095094424585113, eval_sharp=-0.053568168750496206\n",
      "\t train_loss=0.0005589593008452714, train_sharp=0.019390794377973183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████████████████▊                                                                                                                                                                              | 6/50 [15:05<1:50:33, 150.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, run_time=74.29353499412537, train loss=0.0005582938668887877, eval_loss=0.0007607305160490796, eval_sharp=0.05151548619195696\n",
      "\t train_loss=0.0005576281871766673, train_sharp=0.028628324086737086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████████████████▋                                                                                                                                                                          | 7/50 [17:36<1:48:07, 150.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, run_time=74.44740104675293, train loss=0.0005577160165716043, eval_loss=0.0007111627292033518, eval_sharp=0.07292169991766413\n",
      "\t train_loss=0.000557924909224323, train_sharp=0.03694629339458827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████████████████████████████▋                                                                                                                                                                      | 8/50 [20:02<1:44:33, 149.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, run_time=71.95731210708618, train loss=0.0005581584879810349, eval_loss=0.0007469993233826244, eval_sharp=0.06086014462157764\n",
      "\t train_loss=0.0005571026175976326, train_sharp=0.02928003614072748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████████████████████████▋                                                                                                                                                                  | 9/50 [22:33<1:42:24, 149.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, run_time=74.3683705329895, train loss=0.0005579268076617606, eval_loss=0.0007553175837529125, eval_sharp=0.06775455922184492\n",
      "\t train_loss=0.0005573443762932019, train_sharp=0.030173550633276095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████████████████████████▍                                                                                                                                                             | 10/50 [25:03<1:40:02, 150.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, run_time=74.1704113483429, train loss=0.0005576050349891544, eval_loss=0.0007283579325303435, eval_sharp=0.07485552019798729\n",
      "\t train_loss=0.0005573996649845358, train_sharp=0.040530070468550346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████████████████████████▎                                                                                                                                                         | 11/50 [27:35<1:37:51, 150.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, run_time=75.19064378738403, train loss=0.0005575508277491603, eval_loss=0.0007508639519073768, eval_sharp=0.052355319180367864\n",
      "\t train_loss=0.0005572190789252039, train_sharp=0.02833925394112974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████████████▎                                                                                                                                                     | 12/50 [30:05<1:35:18, 150.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, run_time=73.8664128780365, train loss=0.0005579973577871711, eval_loss=0.0007401747825497296, eval_sharp=0.05211739635461216\n",
      "\t train_loss=0.0005570265387838579, train_sharp=0.029235806917848342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████████████████████████████████████▏                                                                                                                                                 | 13/50 [32:34<1:32:27, 149.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, run_time=72.88722372055054, train loss=0.0005575453818982513, eval_loss=0.0007560723661299562, eval_sharp=0.04127396265042399\n",
      "\t train_loss=0.0005574450832744627, train_sharp=0.028851268730471058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████████████████████▏                                                                                                                                             | 14/50 [35:05<1:30:04, 150.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, run_time=73.66505861282349, train loss=0.000557896625724193, eval_loss=0.0007287971384357661, eval_sharp=0.07868833465160706\n",
      "\t train_loss=0.000557444530301684, train_sharp=0.04248056106982454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████████████████                                                                                                                                          | 15/50 [37:41<1:28:37, 151.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, run_time=74.59049606323242, train loss=0.0005574358279400314, eval_loss=0.0007461178411176661, eval_sharp=0.055988232053929964\n",
      "\t train_loss=0.0005571287438441184, train_sharp=0.028755567360462236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████████████████████████████████████████                                                                                                                                      | 16/50 [40:17<1:26:46, 153.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, run_time=76.53999948501587, train loss=0.0005575799735180559, eval_loss=0.00076121251549921, eval_sharp=0.05417051669287516\n",
      "\t train_loss=0.0005575288872119554, train_sharp=0.028901195732092013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████████████████████████████████████████████████████████▉                                                                                                                                  | 17/50 [42:53<1:24:47, 154.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, run_time=75.88414597511292, train loss=0.0005574451586099989, eval_loss=0.0007369642626144923, eval_sharp=0.06537697426995522\n",
      "\t train_loss=0.0005570047521263777, train_sharp=0.03014478111137218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████████████████████████████████████████████▉                                                                                                                              | 18/50 [45:28<1:22:22, 154.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, run_time=75.32902383804321, train loss=0.0005576482257966288, eval_loss=0.0007543810988863697, eval_sharp=0.0589132537806705\n",
      "\t train_loss=0.0005572616777589591, train_sharp=0.029132564441774818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████████████████████████████████████▊                                                                                                                          | 19/50 [48:05<1:20:08, 155.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, run_time=76.9324688911438, train loss=0.0005577236777482415, eval_loss=0.0007291607216757257, eval_sharp=0.06592890267307167\n",
      "\t train_loss=0.0005571447158816577, train_sharp=0.0318278037927052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 20/50 [50:39<1:17:27, 154.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, run_time=74.99009776115417, train loss=0.0005576231607101476, eval_loss=0.0007400504036922939, eval_sharp=0.06269841116030443\n",
      "\t train_loss=0.0005569965943317391, train_sharp=0.029399780500482257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                  | 21/50 [53:14<1:14:48, 154.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, run_time=75.42562007904053, train loss=0.0005576561891288722, eval_loss=0.0007469358115486102, eval_sharp=0.05664017761477171\n",
      "\t train_loss=0.0005570720609256517, train_sharp=0.028509461343008996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 22/50 [55:50<1:12:25, 155.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, run_time=77.24093317985535, train loss=0.0005576433145704315, eval_loss=0.0007330235002882546, eval_sharp=0.051523839601601784\n",
      "\t train_loss=0.0005570867792840596, train_sharp=0.029631806576542897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                          | 23/50 [58:29<1:10:24, 156.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, run_time=78.27623653411865, train loss=0.0005576527519845722, eval_loss=0.0007248266065289499, eval_sharp=0.049470915311369046\n",
      "\t train_loss=0.0005573289621544002, train_sharp=0.027755956475121992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 24/50 [1:01:04<1:07:33, 155.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, run_time=75.37250924110413, train loss=0.0005573232188026901, eval_loss=0.0007360044819506584, eval_sharp=0.05900515462259212\n",
      "\t train_loss=0.0005570139812040923, train_sharp=0.029376794208349936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 25/50 [1:03:42<1:05:09, 156.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, run_time=76.35905504226685, train loss=0.0005586121794594139, eval_loss=0.0007571923306386452, eval_sharp=0.0688625216186167\n",
      "\t train_loss=0.0005574651542972912, train_sharp=0.030051778615894795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 26/50 [1:06:17<1:02:23, 155.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, run_time=75.45817971229553, train loss=0.0005577184093222369, eval_loss=0.0007402772243949585, eval_sharp=0.05794427661990319\n",
      "\t train_loss=0.0005570152253024599, train_sharp=0.029768823950561282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                         | 27/50 [1:08:57<1:00:19, 157.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, run_time=79.00955772399902, train loss=0.0005576273750713361, eval_loss=0.0007470830641977955, eval_sharp=0.01856816131155461\n",
      "\t train_loss=0.0005573737007523858, train_sharp=0.0255368867455804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                      | 28/50 [1:11:35<57:41, 157.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, run_time=76.13463258743286, train loss=0.0005577921000401842, eval_loss=0.0007470151704183081, eval_sharp=0.06300690737797457\n",
      "\t train_loss=0.0005570730187309044, train_sharp=0.02894537294916884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                  | 29/50 [1:14:11<55:00, 157.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, run_time=77.08276987075806, train loss=0.0005574761404509812, eval_loss=0.0007479410596715752, eval_sharp=0.06400456431257988\n",
      "\t train_loss=0.000557097078966966, train_sharp=0.030139932341257756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                              | 30/50 [1:16:48<52:21, 157.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, run_time=75.85027599334717, train loss=0.0005581898352468201, eval_loss=0.0007316043993341736, eval_sharp=0.06363929180306402\n",
      "\t train_loss=0.0005570805681922172, train_sharp=0.03046761037735787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                          | 31/50 [1:19:27<49:54, 157.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, run_time=77.63250374794006, train loss=0.0005575164657965394, eval_loss=0.0007352147222263739, eval_sharp=0.062311602603139046\n",
      "\t train_loss=0.000557024067489037, train_sharp=0.028552752903438713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 32/50 [1:22:04<47:16, 157.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, run_time=76.8289623260498, train loss=0.0005578039919376165, eval_loss=0.0007444800467055757, eval_sharp=0.06220033104122154\n",
      "\t train_loss=0.0005570374988616005, train_sharp=0.028387298299133605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 33/50 [1:24:41<44:35, 157.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, run_time=75.91895842552185, train loss=0.0005573439691107292, eval_loss=0.0007313299047382316, eval_sharp=0.03740245027127617\n",
      "\t train_loss=0.0005572262853770864, train_sharp=0.027574828947250156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 34/50 [1:27:16<41:45, 156.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, run_time=75.78026866912842, train loss=0.0005575974247894128, eval_loss=0.0007404208063235274, eval_sharp=0.06733484042795944\n",
      "\t train_loss=0.000557019303860837, train_sharp=0.030512840084385005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 35/50 [1:29:51<39:00, 156.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, run_time=75.55309391021729, train loss=0.0005579469637816587, eval_loss=0.000750496685213875, eval_sharp=0.0644173684664807\n",
      "\t train_loss=0.0005571492689138174, train_sharp=0.030216325826747773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 36/50 [1:32:25<36:16, 155.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, run_time=75.32653403282166, train loss=0.0005572477703760754, eval_loss=0.0007346394613705343, eval_sharp=0.04825730201017087\n",
      "\t train_loss=0.0005570848826543133, train_sharp=0.029178844928308877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 37/50 [1:35:01<33:44, 155.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, run_time=75.75541496276855, train loss=0.0005573709260365746, eval_loss=0.000736224748834502, eval_sharp=0.06329410161488051\n",
      "\t train_loss=0.0005570293069015957, train_sharp=0.029225956176869475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 38/50 [1:37:35<31:01, 155.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, run_time=74.7986912727356, train loss=0.0005574473084973009, eval_loss=0.0007346772836172022, eval_sharp=0.04668713845763286\n",
      "\t train_loss=0.0005570827624131492, train_sharp=0.02981055963205193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 39/50 [1:40:08<28:20, 154.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, run_time=74.07793641090393, train loss=0.000557661343851092, eval_loss=0.0007271641625266057, eval_sharp=0.05873135578219239\n",
      "\t train_loss=0.0005572029480367887, train_sharp=0.02856286355363293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 40/50 [1:42:42<25:41, 154.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, run_time=74.6655285358429, train loss=0.0005575626532139361, eval_loss=0.0007293764865607955, eval_sharp=0.06665018035369324\n",
      "\t train_loss=0.0005571554401912582, train_sharp=0.032478246564918045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 41/50 [1:45:16<23:07, 154.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, run_time=75.04722285270691, train loss=0.0005572993345001875, eval_loss=0.0007193938472482841, eval_sharp=0.06226522610403223\n",
      "\t train_loss=0.0005574921716452194, train_sharp=0.029218543175350754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 42/50 [1:47:49<20:30, 153.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, run_time=74.40124130249023, train loss=0.0005574186792762036, eval_loss=0.0007431535395880928, eval_sharp=0.0633663075872981\n",
      "\t train_loss=0.0005570296837600463, train_sharp=0.02998792870517568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 43/50 [1:50:20<17:52, 153.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, run_time=74.05648946762085, train loss=0.0005578652667987987, eval_loss=0.0007556592045148136, eval_sharp=0.06122589002631041\n",
      "\t train_loss=0.0005573253357448176, train_sharp=0.028633353040840092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                       | 44/50 [1:52:52<15:16, 152.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, run_time=73.93094372749329, train loss=0.0005578771901500602, eval_loss=0.0007469177180610131, eval_sharp=0.06279364245860249\n",
      "\t train_loss=0.0005570778648802137, train_sharp=0.029379187994158437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 45/50 [1:55:25<12:44, 152.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, run_time=74.91890239715576, train loss=0.0005572683848361109, eval_loss=0.0007307904706976842, eval_sharp=0.06367935315075372\n",
      "\t train_loss=0.0005571043037669155, train_sharp=0.029603448149524435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏               | 46/50 [1:57:58<10:11, 152.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, run_time=74.50799441337585, train loss=0.000557525171186075, eval_loss=0.0007473753321391996, eval_sharp=0.06390591756104687\n",
      "\t train_loss=0.0005570897813622481, train_sharp=0.02967950518056667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏           | 47/50 [2:00:32<07:39, 153.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, run_time=74.69656300544739, train loss=0.0005573245024443054, eval_loss=0.0007445434039254906, eval_sharp=0.06088990726315684\n",
      "\t train_loss=0.0005570526890726384, train_sharp=0.028404997865814754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 48/50 [2:03:02<05:04, 152.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, run_time=74.73951601982117, train loss=0.0005573821332709146, eval_loss=0.0007259069298015675, eval_sharp=0.06515908844563374\n",
      "\t train_loss=0.0005572584344895545, train_sharp=0.03438855580098056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 49/50 [2:05:33<02:31, 151.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, run_time=72.50665831565857, train loss=0.0005576550337429569, eval_loss=0.0007546218803327065, eval_sharp=0.06173431177772263\n",
      "\t train_loss=0.0005572896232208098, train_sharp=0.028457214605901306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [2:08:05<00:00, 153.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, run_time=73.99673342704773, train loss=0.0005578000221570653, eval_loss=0.0007426362026308198, eval_sharp=0.06612586393590573\n",
      "\t train_loss=0.000557039191041457, train_sharp=0.030196396299109116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "output_dir = \"output_lstm\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 512\n",
    "seq_len = 14\n",
    "num_layers = 2\n",
    "input_size = 5\n",
    "lstm_dim = 128\n",
    "dropout = 0.\n",
    "\n",
    "# Check wheter GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model Instantiation\n",
    "model = LSTM(d_feat=input_size, hidden_size=lstm_dim, num_layers=num_layers, dropout=dropout)\n",
    "model.to(device)\n",
    "model.train()\n",
    "# setting optimizer\n",
    "lr = 0.001\n",
    "weight_decay = 1.0e-05\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# setting criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "def train_epoch(train_df, model, seq_len=30, batch_size=512):\n",
    "    groups = train_df.groupby(['SecuritiesCode'])\n",
    "    total_loss = 0.\n",
    "    iteration = 0\n",
    "    model.train()\n",
    "    \n",
    "    def collect_batch_index():  # index for a stock with seq_len continuous days\n",
    "        batch_index = []\n",
    "        for sc, group in groups:\n",
    "            indices = np.arange(len(group))\n",
    "            for i in range(len(indices))[:: seq_len]:\n",
    "                if len(indices) - i < seq_len:\n",
    "                    break\n",
    "                batch_index.append(group.index[i: i + seq_len])\n",
    "        return batch_index\n",
    "            \n",
    "\n",
    "    batch_index = collect_batch_index() \n",
    "    indices = np.arange(len(batch_index))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for i in range(len(indices))[:: batch_size]:\n",
    "\n",
    "        # if len(indices) - i < batch_size:\n",
    "        #     break\n",
    "        \n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for index in indices[i: i + batch_size]:\n",
    "            values = train_df.loc[batch_index[index]].values\n",
    "            x_train.append(values[:, 3: 3 + input_size].astype(np.float32))\n",
    "            y_train.append(values[:, -1][-1])\n",
    "        \n",
    "        # print(y_train)\n",
    "            \n",
    "        feature = torch.from_numpy(np.vstack(x_train).reshape((len(y_train), seq_len, -1))).float().to(device)\n",
    "        label = torch.from_numpy(np.vstack(y_train)).flatten().float().to(device)\n",
    "        # print(feature.size(), label.size())\n",
    "\n",
    "        pred = model(feature)\n",
    "        # print(pred.size(), label.size())\n",
    "        loss = criterion(pred, label)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # if list(label.size())[0] < batch_size:\n",
    "        #     print('train', pred.size(), label.size(), feature.size())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 3.0)\n",
    "        optimizer.step()\n",
    "        iteration += 1\n",
    "            \n",
    "    return total_loss/iteration\n",
    "\n",
    "\n",
    "def test_epoch(train_df, model, seq_len=30, batch_size=512):\n",
    "    groups = train_df.groupby(['SecuritiesCode'])\n",
    "    total_loss = 0.\n",
    "    iteration = 0\n",
    "    model.eval()\n",
    "    \n",
    "    tmp_df = train_df.copy()\n",
    "    tmp_df['pred'] = 0  # 默认没预测的涨幅都为 0\n",
    "\n",
    "    def collect_batch_index():  # index for a stock with seq_len continuous days\n",
    "        batch_index = []\n",
    "        for sc, group in groups:\n",
    "            indices = np.arange(len(group))\n",
    "            for i in range(len(indices))[:: seq_len]:\n",
    "                if len(indices) - i < seq_len:\n",
    "                    break\n",
    "                batch_index.append(group.index[i: i + seq_len])\n",
    "        return batch_index\n",
    "\n",
    "\n",
    "    batch_index = collect_batch_index()\n",
    "    indices = np.arange(len(batch_index))\n",
    "    \n",
    "    pre_indices = [index[-1] for index in batch_index]\n",
    "    pred_array = np.array([])\n",
    "    \n",
    "    for i in range(len(indices))[:: batch_size]:\n",
    "\n",
    "        # if len(indices) - i < batch_size:\n",
    "        #     break\n",
    "\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for index in indices[i: i + batch_size]:\n",
    "            values = train_df.loc[batch_index[index]].values\n",
    "            # see the train_df format upstair\n",
    "            x_train.append(values[:, 3: 3 + input_size].astype(np.float32))\n",
    "            y_train.append(values[:, -1][-1])\n",
    "\n",
    "            \n",
    "        feature = torch.from_numpy(np.vstack(x_train).reshape((len(y_train), seq_len, -1))).float().to(device)\n",
    "        label = torch.from_numpy(np.vstack(y_train)).flatten().float().to(device)\n",
    "        \n",
    "\n",
    "        pred = model(feature)\n",
    "        \n",
    "        loss = criterion(pred, label)\n",
    "        \n",
    "        # if list(label.size())[0] < batch_size:\n",
    "        #     print('test', pred.size(), label.size(), feature.size())\n",
    "        total_loss += loss.item()\n",
    "        # print(pred)\n",
    "        pred_array = np.append(pred_array, pred.detach().cpu().numpy())\n",
    "        iteration += 1\n",
    "\n",
    "    # print(len(pre_indices), len(pred_array))\n",
    "    tmp_df.loc[pre_indices, 'pred'] = pred_array\n",
    "    tmp_df['Rank'] = tmp_df.groupby(\"Date\")['pred'].transform('rank', ascending=False, method=\"first\") - 1\n",
    "    tmp_df['Rank'] = tmp_df['Rank'].astype(int)\n",
    "    \n",
    "    sharp = calc_spread_return_sharpe(tmp_df)\n",
    "    \n",
    "    return total_loss/iteration, sharp\n",
    "\n",
    "\n",
    "log_train = [[0], [np.inf]]\n",
    "log_eval = [[0], [np.inf]]\n",
    "best_eval_loss = np.inf\n",
    "best_model_path = 'Unknown'\n",
    "\n",
    "if True:\n",
    "    model.eval()\n",
    "    train_loss, train_sharp = test_epoch(train_df, model, batch_size=batch_size, seq_len=seq_len)\n",
    "    test_loss, test_sharp = test_epoch(test_df, model, batch_size=batch_size, seq_len=seq_len)\n",
    "    print(\"with training, random train_loss={}, train_sharp={}, eval_loss={}, eval_sharp={}\".format(train_loss, train_sharp, test_loss, test_sharp))\n",
    "    _tqdm = tqdm(range(epochs))\n",
    "    for epoch in _tqdm:\n",
    "        epoch_loss = 0.0\n",
    "        # set iteration counter\n",
    "        iteration = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        epoch_loss = train_epoch(train_df, model, seq_len=seq_len, batch_size=batch_size)\n",
    "        end_time = time.time()\n",
    "    #     print('epoch_loss={}'.format(epoch_loss))\n",
    "\n",
    "        log_train[0].append(epoch)\n",
    "        log_train[1].append(epoch_loss)\n",
    "\n",
    "        # eval\n",
    "        eval_loss, sharp = test_epoch(test_df, model, seq_len=seq_len, batch_size=batch_size)\n",
    "        train_loss, train_sharp = test_epoch(train_df, model, seq_len=seq_len, batch_size=batch_size)\n",
    "        \n",
    "        log_eval[0].append(epoch)\n",
    "        log_eval[1].append(eval_loss)\n",
    "        if best_eval_loss > eval_loss:\n",
    "            best_eval_loss = eval_loss\n",
    "            best_model_path = f\"{output_dir}/{epoch}.pt\"\n",
    "\n",
    "        # print(\"epoch {}, run_time={}, train loss={}, eval_loss={}\".format(epoch, (end_time - start_time), epoch_loss, eval_loss))\n",
    "        print(\"epoch {}, run_time={}, train loss={}, eval_loss={}, eval_sharp={}\".format(epoch, (end_time - start_time), epoch_loss, eval_loss, sharp))\n",
    "        print(\"\\t train_loss={}, train_sharp={}\".format(train_loss, train_sharp))\n",
    "        # _tqdm.set_description(\"epoch {}, run_time={}, train loss={}, eval_loss={}, eval_sharp={}\".format(epoch, (end_time - start_time), epoch_loss, eval_loss, sharp))\n",
    "        # save mode\n",
    "        save_path = f\"{output_dir}/{epoch}.pt\"\n",
    "        param = copy.deepcopy(model.state_dict())\n",
    "        torch.save(param, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_lstm/0.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_model_path)\n",
    "# best_model_path = \"output_lstm/17.pt\"\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEGCAYAAADMsSqUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhU5ZX48e/p6oW92VpEdgQ0YASxRXCJEKOCicEYEjFuMRonDk7MOmomY2bMmOhjfpNMEjORRI1xVDC4YeIuatyhQRDBAC2ggArN1qy9VNX5/XFu0UVTVV1d3dUXmvN5nn6q6ta9b91bXVXnvu973veKquKcc86FoSDsHXDOOXf48iDknHMuNB6EnHPOhcaDkHPOudB4EHLOOReawrB34FDTu3dvHTx4cNi74Zxzh4yFCxduVtWyVM95EGqmwYMHU1FREfZuOOfcIUNEPkj3nDfHOeecC40HIeecc6HxIOSccy40HoScc86FxoOQc8650HgQcs45FxoPQs4550LjQci1X2tfhQ0Lw94L51wGHoQOB/d8Hl79Zdh70bbq9sCsi2HudWHviXMuAw9C7V20Dj58HT54Pew9aVvvzoGa7bBxKezeHPbeOOfS8CB0sPr4Hai4u+Xl7NgAGodtaWfNaH9U4a2Z0KHUHq/5e7j745xLy4PQwWjvdnjwIvjr96xZqSW2fxjcfmA/zoeDD9+0GtCZN0FJKax+Kew9yo/FD9ixOncI8yB0MHryB7BjPaCwZVXLykoEoWgN7NrY4l3Lu11VsOjPLQuY8++0WtDoi2Dwae0zCNXsgLnfts+KOzRFa8Peg4OCB6GDzTt/gaV/geO+bI+rVrasvEQQgpY3yVWthAcutECRLy/9DOb+C1T9I7ftd3wEy+fCCZdCcWcYOtFqgVvXtOZehu/9eRCvh0+WWtOtO7RsWwu3D4eXbgt7T/YXq7e/NuRB6GCyfR387fvQfxx88bcgEdi8ooVlfggS/Ju3tyAI1e6C2ZfAyqftLx9qd8I7D9n9D9/IrYyKe6wP7KSr7PHQiXa75uWmt92wEO46x5pDD3Yrn7baXqQYFt8f9t645nr5dqithpd+Dquz+Gy2lfu+ZN/zNuRB6GARj8Gj3wKNwQV3QnEn6Dkk9xpBwvYPoe8Yu59rTUgVnvi2NQ0Wdco9QDRl6Ryo22U/rLn0dURrYeE9MOIce+8Aeg+Hrn2z+6K/8TtY92Z2AStM8RisfAZGTIZjzrXAHa0Le69ctjZXwpIH4MSv2+fzkasPjgzOuj323V75dJsGxrwGIRGZLCIrRKRSRG5I8XyJiMwOnn9LRAYnPXdjsHyFiJzTVJki8oqILA7+PhKRx4LlE0WkOum5m7Ldvzb1xm/hg1dhym3Qc6gt631M6zTHlR0DXfrA9rW5lTF/Jrz7MHz2x3D0Z/OX7r3wHuhznAWRXALdssdgdxWMu7phmYjVhta8DPF4+m1rdsA//mr317zS/NduS+vmw96tcMwUOOESu7/yqbD3ymXr5VuhsANM+jFMuxv2brMT0Eyfz7bw0dsQj0JBITz/H22WyJS3ICQiEeAOYAowErhIREY2Wu1KYJuqDgN+CdwWbDsSmA6MAiYDvxORSKYyVfV0VR2jqmOAN4BHkl7nlcRzqnpzM/avbXz8DrzwU/jUeTDm4oblZcfA1vdzb6ON1sHOj6D7QOg+KLea0LoF8My/2Vn3qd+FgRNg2xrY+Ul22695BTYua3q9DYvg4yV2djjwFAue1Ruat6/zZ0KvYTB00v7Lh06EPVtg47vpt13+uCVvdOsHaw/yILTiSSgogqPPtJOCrn3h7cOoSS5a2+b9Fq1m03tW4x93NXQpgyM/DefcApXPwZu/C3ff1s+328/9B3y0yL4TbSCfNaFxQKWqrlbVOmAWMLXROlOBe4P7c4AzRUSC5bNUtVZV1wCVQXlNliki3YDPAo+1wv7lX/1eeOSb0KkXfOF/7Mw9oewYOzPJtVM9MUao+0DoMaj5fUK7N8NfLoduR8GXfg8FBTBogj2XTW0oHoOHLrVkhqZSzRfeY019x38VBo63Zeua0SS3YSFsqLAvd0Gjj/WQM+w2UzPbklkWwMZ905pAd23K/rXb2sqnLeuvQzcoiMDo6fYjlu2JwaEsVg93n2NDGA5FL/0cirvAqUkzeZx0FRz7Bat9hDnN1LoF0PNoGP/PUPYpmPdTiEXz/rL5DEL9gHVJj9cHy1Kuo6pRoBrolWHbbMo8H3hBVXckLZsgIktE5CkRGdWM/QNARK4WkQoRqaiqauXMsJd+bj96598BnXvt/1zvEXaba79QIjOu+0DoMdhqFtl+qOIxePgqC0Rf/TN07GHLjxwNRZ2zay7bsNCaGqrXwSv/L/16NdV2dnjcl62z/cjjg9doRhCa/wf7co9O8ePUra81baZL1d621ppCR0+HwZ+xZQfrANct78PmldYUlzDmEjvZWDIrvP1qK2/cYc1Glc9Z38qh5ON3rHYx/hro1LNhuQh88TfWZD7nG9Y03NZUYd1bMGCcndiceRNsqYS378v7S7fHxISLgAeTHi8CBqnqaOA3NF1DOoCqzlTVclUtLysra6XdDKx4GoafDcM+d+BziSCUa4ZcchDqPsiSHnasz27bl2+D1S/CubfDUWMalkcKYcBJ8EEWQWjVc5aZd8y58Pqv7Qc0lXcegvo9UH5Fw2v0L8++X2hXlfVZjb7IagepDJ1otbdUHfiJjLzjL4S+o6G468HbJLci6PsZMblhWe9hMOBky5JraTt+7S5rFn33Efj77fDEdbBxecvKbC1bV9tJ25DPWL/FwnvC3qPmefFndpI1YcaBz3XqCdPusgzZv363ef9H1ZYnpmxbA3s2WxACO8kZMB5eurXlA+abkM8gtAEYkPS4f7As5ToiUgiUAlsybJuxTBHpjTWz/S2xTFV3qOqu4P6TQFGwXjb7l1+xqH2xjkjTFVXSBUoH5J6ckEjP7tbPmuMgu36hNa9YEBpzMYy97MDnB06w/pWa6szlVD4H/U+CL/zKOmKf/OGBXy5VWPgnq/0cNXb/1/gki9cAWPQniNXtn5DQ2NAzLNCtX3Dg6y95EAafbsE6UgiDTml5csKSWQ3BrTWteAqOGNXw/0wYc7HVkNZXpN92+VyYORF+f7rd/uFMuOtsuHsy/PEs+MUI+Hk/uPMzMOcKmPdfNnD4pZ+1/nE0lyo88R3LnPzSnXDs5y3o1teEvWfZWb/QkkdO+Rfo2D31OgPHw8Qbbd7D5tRqF90LP+sLD3/Taom5WBd8L/oHQUjE+oZ2fQJv/T63MrOUzyC0ABguIkNEpBhLNJjbaJ25wOXB/WnAPFXVYPn0IHtuCDAcmJ9FmdOAv6rqvk+miBwZ9DMhIuOwY96S5f7l1/YPbMBh7+Hp1+k9omU1oW79IFJkNSGwpqemLH/cmrbO/cX+fVQJAycAalla6eyqsi/EsLOgax+Y9CN4/4WGDLSE9RUW0Mq/sf9rDUq8RqOg0Vg8ZmODhk6CshHp1xt8mgXkxk1y6xfYicDo6Q3LhpxuCSE7Psr82ulU3AOP/pPNaNCaqbd7t1ntMLkpLmHUl6CwIyz+v9TbrnzGAkvdbuvj69Tbao1FHa1WUdTB/ldn3gRfuRe+9Sr86CPrH1jxVPh9ZEsetD69z/3E9r/8G/Z+vNe2X9mcvXgLdOwJJ38r83qnf89Oxv5+e3a1IVV48/fWp7ziKTu5uHsKvPeEfTeytX6+tQAc8amGZYMmWI371V/Bnq3Zl9VMeQtCQR/PtcAzwHvAQ6q6TERuFpEvBqvdBfQSkUrge8ANwbbLgIeA5cDTwAxVjaUrM+llp7N/UxxYYHpXRJYAvwamq2mqrPzbHEzJ0zvDj2dZkKadS/rm9g/t7B4sGEkku+SETcuhzygbq5RK/5PshytTcsL7L9jt8KCZ8aRv2hn80zfuX71feI8FvE9P23/7fuW2v001ya1+0RIwEk156XQohX4nHhiEFj9gP96f+mLDssGn220utaF3H7bmlAHjIbrX+qpay6rnrUk1VRDq0A1GTrVmtMbNJ2tegYcus/T3q16Ar82GS+bApY/CZY/D1/8Klz9h/ZKnfx9GnW9ZW8WdYezllhyz+IGW7Xs8lr45tim7quCZH1mT44nfsGWDP2NDGVpjkt98+/BN+z6c9h0o6Zp53YIInPxPdhK09tWmy96wCKreg4k3wPeWwzk/syb32ZfAb8bCW3dm99uxbj70G2uvn+zMm6B2R14vBZPXPiFVfVJVR6jq0ap6S7DsJlWdG9yvUdWvqOowVR2nqquTtr0l2O4YVX0qU5lJz01U1acbLfutqo5S1dGqOl5VX8+mrDaRmBeu17D06/QeYT9m1evSr5NOchCKFEJp/6ab41StZtJnVPp1ijvZANhMAWLVc9C5zBIZEq//+V/sn6Swd5v9aH/6Kwd+OUu6QN/jm05OWPwgdOi+fx9JOkPOsGSJRMdvfQ0se8RS45P7ko78tAWttc1MTlj1vA08HDjBfuCPOdfSxut2N6+cdFY8CZ2P2L/ZMtkJF9sPRnJtc/1CeHC6JaZc8kj6PrN0ykbY8bR0Pr8nfwC/OTG37K9nbrS+qvN+3ZD5WFAAJ15hn8FN7+W+X21h3n/Z/+2kb2a3/sip9vlb+Kem1337z3YSddyX7X87YQb8y9uWTNT5CHjqX+0znkntLhtGkegPStZnlPWVzp/Z/CETWWqPiQmHjs0rrRqdnCnTWNmxDes2R/IYoYRs0rR3bLB+mHT9VAmDJtgPSqo2+XjMzvyGfW7/dOlBp9gHOpGksGS2jc1JV4sZOMHSrtN1utZU2w/up6dBYUnm/QVLTtAYfPCaPV75tJWR3BQHdjY46LTm1YQ+fNPOPo/4FHxtlgXqU6+zgaStMYYnWgeVL9hA3sYp6AmDTrP/d2Ian43L4f8ugM694dLHDsy+zNbYy+3MPNdByqueC2osCn//RfO3XfoXa6Y64tj9nxtzsfURVRzECQrr5luSy+nfS9+y0FhRRzh+ujU17t6Sfr263bD0Yau5Ji5bAnbCN3IqfOMZ6HqUnehl8tEi+170TxGEwJrSNW5JIXngQShMmyszN8WBNccBVDWzXyh5jFBCNgNWEwNL+xyXeb2Bp1gywEeLDnxuwyKr5aTK+Dvrpw1JCgvvsbP6vqPTvMZ4C1IfL0n9/LLH7PnRX8u8rwkDxtlZY2JKkiWzoMuRDfPLJRvyGQvYyRPApvPJUrj/q1DaDy55tOEHYeB4a0J64zctH2/x4es211iqpriEggL7YV79sv3dd779oF32uKWp52rkVLskxqJ7m163sd1b4PEZdlJz+vetNvfJ0uy2rdttlzPpPcK2baxzL9u3JbPynsGVs5VPW7PymCw/owknXm7fryWNexeSLH8c6nbaZL2pFBTAcRdYIN+7LX05ib7d/uWpn+8xCMqvtD65PLzPHoTCtGVV5qY4sFpSp97NHyuUnJ6d0GMQ7N6U+YOUmFWgTxM1ocSA0lRnx5VBavbRnz3wua59LAPo/RfsmDL15QwMBsama/Zb8iD0Gm5t2dkoLLEa3OqXrJ+h8jkbHNu4HRwsOQGarg1ted8mfSzpYrWNLo1S+E+9zv4Xy5s9MmB/K5624D10Yub1Rl8EqAWgWL3tU4/BLXvt4k5w/FfsRy/Tj1ljqvC371qn9gUz4ZRvQ0m37GtDL/4Mqj+0Zrh0Nd0Tr7Dg3FSTU1jef9H6UJNrKtnoM8pqJovuTd8Muug+G1w66JT05Rx3gSU//eNv6ddZv8ACfaYWmUk/ghkLsq/NNYMHobDs3WbznGXKjEsoO6b5zXEpg9CQ/Z9LZeNyKB3Y9JemU09rKkzVZ7PqOUsCSPehHne1JSmUdGu4ZEUqXY6wL1mqILR1tS0fc1HqDL50hk60jtw377AO91SDW8FGjHfqlXm8UN0ea+7SuP3Ydx9w4DojpligfO1/cu9TUbUaxJAzLFkgkx6DLPgXd4FLHzmwCStXYy+zWufSOdlv885DFrgm/cj62Tp2txkplj/edM3+g9dtYOqJVzTM0pHKoFNsIPLB2CS3Z6tliB49qel1Uznxcvvep/r8b6602vEJl2T+/B811k5C0jXJqVoQStcUl9Chm2VQ5oEHobAkRns31RyXWKdqRfN+xJLHCCUk0rQz9QttXJY5KSHZwAk2yjo5FXT35obU7HQihXDxQ5aV1dSP6sAJFugaZ/gsmQ2ItZ03x9CJdvv6b6wZMF2Nr6DA0rrXvJL+fX/tV5by/pU/pU8PLyiAU78Nn7yT+8X1qv5h/7NMTXHJpt0D11bAUSfk9nqp9B1tySgLM5yZJ6teb02uA8bvP0XN+Bk2PVOm2lBNNTzyT/bjefZPM7+OiNWmN1QcfNdVWvN3QA+cyzBbo75kJ2qpEhTevi+7Zj4RO9Fb/XLq64BtXW3zKg44Kbd9bAUehMKyLzMum5rQsVCz3WpO2UoeI5TQ1IDVaK2deTXVFJcw6BTLxkqeoPT9eYA2pGanU9o/fV9QsoHjrXM/+Qqz8bg1xQ09w/phmqPPp228RqZaUMLg0y3ddVuKufu2rbXxE8d92fqPMjn+QpuS5bX/ad6+Jqx40m6zyQAEq3F07ZPba2Uy9jK7bHpTAyLjcXjsGuvs/tLv92/u7NwLTvqGDchMl7L95L9an+YFf2g6pRkssaSww8E3g8LqFy2I9Dsxt+2LO1tz8bLH9h+nE4va53/42dD1yKbLOe7L9r94L8WEpPv6g5qoCeWRB6GwbF5pY20aj3xPJXGW3Zx+oeT07ITOZXYWmq4mVLXCPqzNqQnB/s0Fq56zPqy+rXQWnuo1PnzDjqGpIJJKQYEFDYnAcdMyr5sILqn6hZ75N/txPauJM3Ww/ozx19iPUroki0xWPG21mpYkF7SGT0+zz09TCQrz77RawDk/a7iuU7IJ/2JZba/+94HPvfswvDMLPvPD7M/OO/aAURdY81/tzgOf37UJ1r7W9hcrfP9FO5GJFOZexolfh1jt/rNvVD4HuzbC2DQJCY0dMdJOZN9N0W+27i0LlGWt1GybAw9CYdm8ygbbJddU0umdQ4ZcqiAkYsvSzZqQbWZcQvcBNq1QIjkhHg9Ss89Mn0bcXL2OtqCW3Pe05EHr8/jUebmV+bmfwEUPHphE0FjvEVaDadwv9P48Sw0//fvZ18ROvMJGpL/26+bt69bV1mY/IsumuHzqUGpNREvn2NiSVDYut9mgR0xJPeUTWC1t7OWW1ZZcK69ebwN9+5VbEGqO8ivsgohL58COj+32ie/Ab8rhF8PhT+fCbYPh96fBU9dbv1Q+L1O/dbWdKOXaH5Rw5KetX2fhnxqaQRfdZ2OAhp+dXRmJJrkPXj9wrM/6BVZTa63vaw48CIVl86rsmuLApikp7pp9ckKqMUIJmdK0Ny2DSIklA2Rr4ASrmahaM82eLZn7g5pLxJrkEjWhuj3WPDFyatP9Sen0HGrjbbJ57cb9QrF6+xHrMQQmXJv9a3bsDuVfh2WPZjd1UsKz/261jxMvb3rdtjD2Mvuxb5ztV7cbXvw5/CFIivjirzN3mJ96nfVZvvYrexyP24XdYlHLpGtu7aH/SXby9OQP4b+PhYevtFpVzyFw1s1w0WybVaBjD+vXeugy+MUw+O243K7i25T3X7TbXPuDkp34dUumWTcfdm60tO/R07M7gU0YdQGg+//fanfa7CgDTm75PraAB6EwJCYu7d1EenaCiDXJZVsTSjVGKCExYDVV5/LGZZZN1ZwfgEETrGlg62prJkBSp2a3xKBT7Id7x8eWalq3M7emuFwMPt0mcdwSJJK8daedDEz+efOzhU6+xn5438jy4mWrXw5qXN/Lru2/LQw42WrmC4MmuXjcBuP+eqxdMfSYyfDNeZbZmElpPxvT9Pb/2Rx9b/zWapxTbrXab3OJwOf+05I3zv4vuPoluH4tXPwXC3jHTLYgdPkTcMOHcOXztn6s1maUyHVKoXRWv2itBLkcS2PHfdkC+6J7rRVAY+nHBqXTe5j1wSZnyW1YaL8TISYlgAehcOybuDSLzLiE3sdkH4RSpWcndB9kyQSpxntsXGap080xMBij8OEbDanZuY7MT/sa4xteY8kDlkI+6NTWfY109vUL/d3OQl+61Wp62SYJJCvtZx3Ni+61GcIzicdsnr3uA5tX48o3EasNrZ9vTUQzz4DH/9mO7RvPWqZgNv2cAKd9147zievghZvtwm7N/XFNNvxzcOF9NlP1USekHv8FUFhsP7ynfcemV0Lgga+23iSd8Zh9XoZObN7wgXRKutjUVu8+YskXA8Znnqw3neO+bIEncZHMxOTA/dIMUm0jHoTCsLkZmXEJZSPsjDybSxtkCkI90qRp76qyGk22SQkJvUdYE8c//mYf8OGt2BSXcOTx1iS17BFLcx59Ydu1YfccalOfrH0FXvhPGysz+dbcf1w+9x/2fs2+JHNH+aJ7rXn0rJ/mbXxGzkZfZJcXf+I6O5n58l1WsxjYzGadHoOsWWnVszYm67wmmvDyoedQmP6AfWdmX9ry6/KANUvXVLe8PyjZiZfbHJLb1mafkNDYqC/ZbWJg77q3LCEh3aUl2ogHoTAk0o2zGaiasC85IYt+oVRjhBISo+cb9wttSiQlNDMIFRRYv9CKJwFt3f6ghEiRTSny3hPWfNBWTXFgP4pDToeVz9qcbBP+Oftm1FS6HGGXSqheZ30gqWY43rvdJr0cdKr1fR1sOveCKbdZX8u1CyxrLteTgs/8wDrfL7iz9WvQ2Ro0AabeYVfXfeK6ll8Y8P15gMCQia2xd+aoE4ILLnaBkefnVkb3gdac+u4j9rlbv8D60kLmQSgMm1c1PXFpY4k55LK5tlCqMUIJ6QasJq6emW1mXLJEGnWnXq07QDLVaww4uXXa2Ztj8OlQv9vmmWtu1lYqA0+Gc35uFzl7NcVlz/9+uzUNTf5529cMsnXSldbXUtSxZeX0HGrXLho6sTX2KnfHf9Wmk1ryQPpL0W96D+bdYtlpmbz/os0A39pB9Ut3wkWzrHkuV8d92abmWvE3G3uYaubsNtaCBHaXs+ZkxiX0GGyZa9mMFdr+YUOwaaxDN2sOalwT2rjMxhE1lbacSmLuqqM/m79mssRrtGUtKGHYmTaWYsqt2Q2ezMa4b9qZ6LxbLHAnJnvdXGlXsjzhkuwG87rWc8b1loAy76cWHI+7wPpP3n3Yag+J1gIpsAHdqQah1u60/rJ89OMlX3AuVyPPh6dvsKxLCHWQakJea0IiMllEVohIpYjckOL5EhGZHTz/logMTnruxmD5ChE5p6kyReQVEVkc/H0kIo8Fyy8WkXdEZKmIvC4io5O2WRssXywiGa6L3Mq2rGp+k05BxCY7zao57oPU/UEJ3VNc0qGpawhl0ne0dSqXX5nb9tkYcoadBbak4zpX3Y6C6z9oaFNvDSJw3q9sIOHDVzWcFDz7Y5vp+8ybWu+1XHZE4Iu/tY7/R78FMyfBr8dYUCrpClNuh2sX2tixud+2dP3G1r5ms3G0Zn9Qa+rax4YdbFtj476akxyVJ3kLQiISAe4ApgAjgYtEpPF8MFcC21R1GPBL4LZg25HYVVJHAZOB34lIJFOZqnq6qo5R1THAG0BiePAa4AxV/TTwU2Bmo32YFGzXNiki+yYuzeGfX5bFpb6jdZbymikI9Wg0VigWtRpWLk1xYM1+0+/PPNFkS4lY+m1LRp+3RD5qeMWdLZsrHoeHLrXLM698yvpJmkpxdvlR1MESFXoNs2By1s3wnaVw5TNw8tV28vj5/2cnba+nGHi8+kWbQmjA+Lbf92wlZgrpf1Kog1QT8rkH44BKVV2tqnXALKBxL+tUIDEHyBzgTBGRYPksVa1V1TVAZVBek2WKSDfgs8BjAKr6uqom8pHfBPq38nE2T2Li0uY2x4Flsmz7AOr3pl9nx3pAs6gJfdjQKb51tWV95VoTcrnrdbR1yn+8BGZdbM2u468Je68Ob517wT+/Dt96xfq9Gn+Xjv28JYy8dFtDpmvC+y9a0/HBltGY7FPnQVHnpuc8bCP5DEL9gORrUq8PlqVcR1WjQDXQK8O22ZR5PvCCqu5IsU9XAk8lPVbgWRFZKCJXpzsQEblaRCpEpKKqqoVTfezLjMuhJtR7BKAHfvCTZUrPTugxyAbp7dpoj3PNjHOt45gplvCgMTj7luyuEuvCNeV2CzRPXNdwMle9wVoqWmOWhHzq1BOuWwzj/znsPQHaZ3bcRcABlyMUkUlYELo+afFpqjoWa96bISIpTw1UdaaqlqtqeVlZDh33yTavyn7i0sb2Zchl6BfKJgh1H2y3ieljNi6zCT0TaeCu7U36N7juHfjUF8LeE5eNrn3shOGD1xomdE1cquNg7Q9K1uWI5k37k0f5DEIbgOSrfPUPlqVcR0QKgVJgS4ZtM5YpIr2xJrv9LiMoIscDfwSmquq+i7ar6obgdhPwaLBtfm1eafOO5fIB6DXMMnMyzZyw/UMLKKnGCCU0HrC6cZmVfTA3IbR3IrmdmLjwnHCJNWk9d5P1w65+0TJMmzvryGEun0FoATBcRIaISDGWaDC30TpzgcTMjNOAeaqqwfLpQfbcEGA4MD+LMqcBf1XVmsQCERmIJSlcqqork5Z3FpGuifvA2UATc6m0gi2VuWekFJZYAMuUpr1vjFCGDvzSAYA0JCe0JDPOucOVCJz3PxCrg7/9wGpCQycdFJ39h5K8pRqpalRErgWeASLA3aq6TERuBipUdS5wF3CfiFQCW7GgQrDeQ8ByIArMUNUYQKoyk152OnBro125Cetn+p3lPBANMuH6AI8GywqBB1T16dZ+H/aTmLg0mxmc02nqUt+pLuHQWFEH6NrXakI1O2ybsQfJLM3OHUp6DrXLlz8XpNQfCk1xB5m85ruq6pPAk42W3ZR0vwb4SpptbwFuyabMpOcmplh2FXBViuWrgbYdDbj9AztryiUzLqH3CJsoNBZNXdvZ/qGNqWlKIk1703v2ONf0bOcOd+Nn2IDWj5eEP/PDIcjrjW0pcTmAlgwQKzvWZuBOvtJoQjZjhBISA1Y3Bi2Q2V7S2zm3v0ghfPXPNq1Ot6PC3ptDjlgJ54wAACAASURBVAehtpRoRmvOxKWNHft5CzKPz7CmtGTZjBFK6DHIrjv08WKbkqZ0QNPbOOdS6zHYZgR3zeZBqC1tXgUdezZv4tLGOnSDC/5oszA/+YP9n8smPTuh+yCbkXrls5aUcLBOlOmca9c8CLWllmTGJRt4MpxxA7wzG5bMbljenCCUSAfe9YlnxjnnQuNBqC1tXtmya9EkO/37dnmDv32/4UqJ2YwRSkieZduDkHMuJB6E2sre7TZxaUsy45JFCuGCmTZ49eGrbEbfbMYIJXQ7yq6OCT64zjkXGg9CbaU1MuMa6z7QLgewoQJevi27MUIJBRHoHiQjtMZ1SpxzLgd+Ubu20hqZcakcdwFUvgB//4Vd5bI5l/7tMQTiMUt2cM65EHgQaiv7Ji4d3PplT7nNxg1tfT/7mhDYtVJqd7b+/jjnXJa8Oa6tbFmV+8SlTSnpAl/+IxR1at4loY88Lr8XonPOuSZ4TaitbF7V+k1xyfqNhevX+rVonHOHFK8JtYV4zCYu7dVK6dnpeAByzh1ivCbUFqQAvv22jeFxzjm3jwehtiACpf3D3gvnnDvoeHOcc8650OQ1CInIZBFZISKVInJDiudLRGR28PxbIjI46bkbg+UrROScpsoUkVdEZHHw95GIPBYsFxH5dbD+OyIyNmmby0VkVfDnV3Vzzrk2lrfmOBGJAHcAZwHrgQUiMldVlyetdiWwTVWHich04DbgQhEZiV0ldRRwFPC8iCSmGkhZpqqenvTaDwOPBw+nYJcHHw6cDPwvcLKI9AR+ApQDCiwMytrW6m+Gc865lPJZExoHVKrqalWtA2YBUxutMxW4N7g/BzhT7HrbU4FZqlqrqmuAyqC8JssUkW7AZ4HHkl7jz2reBLqLSF/gHOA5Vd0aBJ7ngMmt+QY455zLLJ9BqB+wLunx+mBZynVUNQpUA70ybJtNmecDL6hq4opvLSnLOedcHrXHxISLgAdbs0ARuVpEKkSkoqqqqjWLds65w1o+g9AGIPma0f2DZSnXEZFCoBTYkmHbjGWKSG+sye5vWexHNvsHgKrOVNVyVS0vKytLtYpzzrkc5DMILQCGi8gQESnGEg3mNlpnLpDISpsGzFNVDZZPD7LnhmBJBfOzKHMa8FdVrWn0GpcFWXLjgWpV/Rh4BjhbRHqISA/g7GCZc865NpK37DhVjYrItdgPewS4W1WXicjNQIWqzgXuAu4TkUpgKxZUCNZ7CFgORIEZqhoDSFVm0stOB25ttCtPAudiyQ17gCuC19gqIj/FAhvAzaq6tVXfBOeccxmJVTxctsrLy7WioiLs3XDOuUOGiCxU1fJUz7XHxATnnHOHCA9CzjnnQuNByDnnXGg8CDnnnAuNByHnnHOh8SDknHMuNB6EnHPOhcaDkHPOudB4EHLOORcaD0LOOedC40HIOedcaDwIOeecC40HIeecc6HxIOSccy40HoScc86FxoOQc8650OQ1CInIZBFZISKVInJDiudLRGR28PxbIjI46bkbg+UrROScpsoMLt99i4isFJH3ROTbwfIfisji4O9dEYmJSM/gubUisjR4zq9U55xzbSxvl/cWkQhwB3AWsB5YICJzVXV50mpXAttUdZiITAduAy4UkZHYpbpHAUcBz4vIiGCbdGV+HRgAHKuqcRE5AkBVbwduD/bpPOC7jS7jPUlVN+fhLXDOOdeEfNaExgGVqrpaVeuAWcDURutMBe4N7s8BzhQRCZbPUtVaVV0DVAblZSrzGuBmVY0DqOqmFPt0EfBgqx2hc865FslnEOoHrEt6vD5YlnIdVY0C1UCvDNtmKvNorBZVISJPicjw5BcSkU7AZODhpMUKPCsiC0Xk6nQHIiJXB+VWVFVVZThk55xzzdGeEhNKgBpVLQf+ANzd6PnzgNcaNcWdpqpjgSnADBH5TKqCVXWmqparanlZWVk+9t055w5L+QxCG7A+moT+wbKU64hIIVAKbMmwbaYy1wOPBPcfBY5v9FrTadQUp6obgttNwTbjsjoy55xzrSKfQWgBMFxEhohIMRYE5jZaZy5weXB/GjBPVTVYPj3InhsCDAfmN1HmY8Ck4P4ZwMrEi4hIabDs8aRlnUWka+I+cDbwbqscuXPOuazkLTtOVaMici3wDBAB7lbVZSJyM1ChqnOBu4D7RKQS2IoFFYL1HgKWA1FghqrGAFKVGbzkrcD9IvJdYBdwVdLufAl4VlV3Jy3rAzxqeRAUAg+o6tOt/kY455xLS6zi4bJVXl6uFRU+pMg557IlIguD/voDtKfEBOecc4cYD0LOOedC40HIOedcaLIKQiJynYh0C+Znu0tEFonI2fneOeecc+1btjWhb6jqDiyNuQdwKZaN5pxzzuUs2yAkwe25wH1BWrRkWN8555xrUrZBaKGIPIsFoWeCQZ7x/O2Wc865w0G2g1WvBMYAq1V1T3A9nivyt1vOOecOB9nWhCYAK1R1u4hcAvwYm/HaOeecy1m2Qeh/gT0iMhr4PvA+8Oe87ZVzzrnDQrZBKBpMLDoV+K2q3gF0zd9uOeecOxxk2ye0U0RuxFKzTxeRAqAof7vlnHPucJBtTehCoBYbL/QJdh2f2/O2V8455w4LWQWhIPDcD5SKyBewK5h6n5BzzrkWyXbanq9iF5X7CvBV4C0RmZbPHXPOOdf+Zdsc92/ASap6uapehl0G+9+b2khEJovIChGpFJEbUjxfIiKzg+ffEpHBSc/dGCxfISLnNFVmMK/dLSKyUkTeE5FvB8sniki1iCwO/m7Kdv+cc87lV7aJCQWquinp8RaaCGAiEgHuAM4C1gMLRGSuqi5PWu1KYJuqDhOR6cBtwIUiMhK7yuoo4CjgeREZEWyTrsyvAwOAY1U1LiJHJL3OK6r6hRz2zznnXB5lG4SeFpFngAeDxxcCTzaxzTigUlVXA4jILCzFO/lHfirwH8H9OcBvxa63PRWYpaq1wJrg8t/jgvXSlXkN8DVVjQM0Cpq57p9zzrk8yjYx4YfATOD44G+mql7fxGb9gHVJj9cHy1Kuo6pRbBaGXhm2zVTm0VgtqkJEnhKR4UnrTRCRJcHyUc3YPwBE5Oqg3IqqqqpMx+ycc64Zsq0JoaoPAw/ncV9aqgTL2isXkQuAu4HTgUXAIFXdJSLnAo8BwzOUcwBVnYkFYcrLy7V1d9s55w5fTfXr7BSRHSn+dorIjibK3oD10ST0D5alXEdECoFSrL8p3baZylwPPBLcfxSrsaGqO1R1V3D/SaBIRHpnuX/OOefyKGMQUtWuqtotxV9XVe3WRNkLgOEiMkREirFEg7mN1pkLXB7cnwbMC6YHmgtMD7LnhmA1l/lNlPkYMCm4fwawEkBEjgz6mRCRccExb8ly/5xzzuVR1s1xzaWqURG5FngGiAB3q+oyEbkZqFDVucBdwH1B4sFWLBAQrPcQliQQBWaoagwgVZnBS94K3C8i3wV2AVcFy6cB14hIFNgLTA8CXcr9y9f74Zxz7kBiv8cuW+Xl5VpRURH2bjjn3CFDRBaqanmq57IdrOqcc861Og9CzjnnQuNByDnnXGg8CDnnnAuNByHnnHOh8SDknHMuNB6EnHPOhcaDkHPOudB4EHLOORcaD0LOOedC40HIOedcaDwIOeecC40HIeecc6HxIOSccy40HoScc86FJq9BSEQmi8gKEakUkRtSPF8iIrOD598SkcFJz90YLF8hIuc0VaaYW0RkpYi8JyLfDpZfLCLviMhSEXldREYnbbM2WL5YRPwiQc4518bydmVVEYkAdwBnAeuBBSIyV1WXJ612JbBNVYeJyHTgNuBCERmJXWV1FHAU8LyIjAi2SVfm14EBwLGqGheRI4L11wBnqOo2EZkCzAROTtqHSaq6udXfAOecc03KZ01oHFCpqqtVtQ6YBUxttM5U4N7g/hzgTBGRYPksVa1V1TVAZVBepjKvAW5W1TiAqm4Kbl9X1W3BOm8C/fNwrM4553KQzyDUD1iX9Hh9sCzlOqoaBaqBXhm2zVTm0VgtqkJEnhKR4Sn26UrgqaTHCjwrIgtF5Op0ByIiVwflVlRVVaVbzTnnXDO1p8SEEqAmuI75H4C7k58UkUlYELo+afFpqjoWmALMEJHPpCpYVWeqarmqlpeVleVn751z7jCUzyC0AeujSegfLEu5jogUAqXAlgzbZipzPfBIcP9R4PjESiJyPPBHYKqqbkksV9UNwe2mYJtxzTxG55xzLZDPILQAGC4iQ0SkGEs0mNtonbnA5cH9acA8VdVg+fQge24IMByY30SZjwGTgvtnACsBRGQgFpwuVdWViRcWkc4i0jVxHzgbeLfVjt4551yT8pYdp6pREbkWeAaIAHer6jIRuRmoUNW5wF3AfSJSCWzFggrBeg8By4EoMENVYwCpygxe8lbgfhH5LrALuCpYfhPWz/Q7y3kgGjTZ9QEeDZYVAg+o6tP5ej+cc84dSKzi4bJVXl6uFRU+pMg557IlIguDk/8DtKfEBOecc4cYD0LOOedC40HIOedcaDwIOeecC40HIeecc6HxIOSccy40HoScc86FxoOQc8650HgQcs45FxoPQs4550LjQcg551xoPAg555wLjQch55xzofEg5JxzLjQehJxzzoUmr0FIRCaLyAoRqRSRG1I8XyIis4Pn3xKRwUnP3RgsXyEi5zRVpphbRGSliLwnIt9OWv7rYP13RGRs0jaXi8iq4C9xhVfnnHNtJG9XVhWRCHAHcBawHlggInNVdXnSalcC21R1mIhMB24DLhSRkdhVVkcBRwHPi8iIYJt0ZX4dGAAcq6pxETkiWH8Kdnnw4cDJwP8CJ4tIT+AnQDmgwMKgrG35eD+cc84dKJ81oXFApaquVtU6YBYwtdE6U4F7g/tzgDPFrrc9FZilqrWqugaoDMrLVOY1wM2qGgdQ1U1Jr/FnNW8C3UWkL3AO8Jyqbg0Cz3PA5NZ+E5xzzqWXzyDUD1iX9Hh9sCzlOqoaBaqBXhm2zVTm0VgtqkJEnhKR4U3sRzb7B4CIXB2UW1FVVZX2gJ1zzjVPe0pMKAFqguuY/wG4u7UKVtWZqlququVlZWWtVaxzzh328hmENmB9NAn9g2Up1xGRQqAU2JJh20xlrgceCe4/ChzfxH5ks3/OOefyKJ9BaAEwXESGiEgxlmgwt9E6c4FEVto0YJ6qarB8epA9NwRLKpjfRJmPAZOC+2cAK5Ne47IgS248UK2qHwPPAGeLSA8R6QGcHSxzzjnXRvKWHaeqURG5FvthjwB3q+oyEbkZqFDVucBdwH0iUglsxYIKwXoPAcuBKDBDVWMAqcoMXvJW4H4R+S6wC7gqWP4kcC6W3LAHuCJ4ja0i8lMssIElNWzN09vhnHMuBbGKh8tWeXm5VlRUhL0bzjl3yBCRhUF//QHaU2KCc865Q4wHIeecc6HxIOSccy40HoScc86FxoOQc8650HgQcs45FxoPQs4550LjQcg551xoPAg555wLjQch55xzofEg5JxzLjQehJxzzoXGg5BzzrnQeBByzjkXGg9CzjnnQuNByDnnXGjyGoREZLKIrBCRShG5IcXzJSIyO3j+LREZnPTcjcHyFSJyTlNlisifRGSNiCwO/sYEy3+YtOxdEYmJSM/gubUisjR4zq9U55xzbSxvl/cWkQhwB3AWsB5YICJzVXV50mpXAttUdZiITAduAy4UkZHYpb5HAUcBz4vIiGCbTGX+UFXnJO+Hqt4O3B7s03nAdxtdxnuSqm5uvSN3zjmXrXzWhMYBlaq6WlXrgFnA1EbrTAXuDe7PAc4UEQmWz1LVWlVdA1QG5WVTZiYXAQ/mfETOOedaVT6DUD9gXdLj9cGylOuoahSoBnpl2LapMm8RkXdE5JciUpL8QiLSCZgMPJy0WIFnRWShiFyd7kBE5GoRqRCRiqqqqnSrOeeca6b2lJhwI3AscBLQE7i+0fPnAa81aoo7TVXHAlOAGSLymVQFq+pMVS1X1fKysrI87Lpzzh2e8hmENgADkh73D5alXEdECoFSYEuGbdOWqaofq6kF7sGa7pJNp1FTnKomtt0EPJpiG+ecc3mUzyC0ABguIkNEpBgLAnMbrTMXuDy4Pw2Yp6oaLJ8eZM8NAYYD8zOVKSJ9g1sBzgfeTbyIiJQCZwCPJy3rLCJdE/eBs5O3cc45l395y45T1aiIXAs8A0SAu1V1mYjcDFSo6lzgLuA+EakEtmJBhWC9h4DlQBSYoaoxgFRlBi95v4iUAQIsBr6VtDtfAp5V1d1Jy/oAj1rMohB4QFWfbvU3wjnnXFpiFQ+XrfLycq2o8CFFzjmXLRFZqKrlqZ5rT4kJzjnnDjEehJxzzoXGg5BzzrnQeBByzjkXGg9CbWRXbTTsXXDOuYOOB6E2UFMf47zfvMq/zllC9Z76sHfHOecOGh6E2sg5o47k4UUb+NwvX+appR+HvTvOOXdQ8CDUBjoURbhhyrE8PuNUjuhawjX3L+Jb9y1k046asHfNOedC5UGoDR3Xr5THZpzK9ZOPZd6KTXzuv19m9oIP8QHDLhdVO2vZurvOPz/ukOYzJjRTa82YsLpqFzc8spT5a7bSo1MRHYsiFBUWUFggFEUKKC4soENhhNJORXTvWET3TkV071RMacciunYoJBZXojElGlei8Tj1MSUai7OrNsqOvfVU761nR43d31FTT0lhhLKuJfTuUkzvLiX217WE4oiwfU8924Nttu+pp3pvHXvrYpQURuhQVECHosi+v45FETqXROhcUmh/xXa/S0khhRGhQIQCAREhIoII7K2PUZ14jT31bN9bx/Y99cTiGhxfsR1fxyJKOxXRqbiQ3bVRdtVG2VVjtztro+yti9KlJPFe2HY9OhdR2rGIAhHqYnGiMaU+FqcuGqc+FgegKFIQ/AmFkQKKIwWIWF9dbTRObX2c2mhwPxojFodYXO1PlXhciatSUCAUFgiRAqGwoCC4FcCuCaKqxNUeNf5a2exQYLNKJUteUey9Lbb3s3NJIcWFdp64aWcNS9dXs3RD9b7bTTtrAejaoZDBvTozsFcnBvfqxKBenSnrUrJv/wqSbgWoT3qPaoP3KRZXOiT9b7uUFNKpOEKn4kK27anjk+oaPtq+l0+qa/h4Rw2fVNdQINCnWweO7NaBPqXBbbcOdOlQyN66KHvqYuyujbG3Psru2hjReJxuHexzvO//3bGIwogdYyyu1NTH2FsfY29djJr6mH0Ggs/BzqTPQ3FhAUd268CRpR3oW2qv26EokvX3Lx78b2NxpS4Wt89C8DmoCW4BIgUFSf9zuy0uLKBjkb03HYoKEGn8P91fNBZnR000+H7V7fseVO+tJxrXlCcRXUoKKetaQlnXEo7o2oFeXYopiuxfZ1BVaqO273WxOCWRCCVF9vkuKMi8T4n3oCYaY0+dvd976uy9r62PNXxGkr5TkQLhvNFHZf0eJ8s0Y4IHoWZqzWl74nHl4UXreXvdduqDH4P6uO67v6cuRnVScNhbH2uyTBHo1qGIbh0LKe1YRLcOFrRq6uNs3lXL5l21bNlVRzR+4P+9KCKUdiymtGMhnYoL930h99bH9n1J64If9paKFFiQaq3y2qviwgJKCgvYWWPZlSJwdFkXju9Xyqh+pQB8sGU3a7fs4cMtu1m3bS+xFP/b1tSrczF9unUgrsrGHTVsa2GyTefiCPVxpS7ass9Cz87FdO9YZCdmwXcpGvyIRpNOKGJ64ElCS3QsitCxOEJxpGC/E8L6xIlMK/0/enYupmNRpCFQ18fSHkdxxD43xYUFKBAPAq4q+06umvt+9+5STMWPz8pp3zMFobxNYOqaVlAgfKV8AF8pH9D0ytiZ+4699eysjRIRoTBiZ+SFEaGooIBIROhUFGnyLCgeV7bvrWfzrlqiMd1Xs+hYFMnqrG5PfYzdtdGgttJwPxa3mkBcteEvDh2LI5QGZ72JGl3nYnutmvpYUBOz2tH2PXXsqYvRuaSQriWFdOlgZ+VdOhTSsSjC7toY2/bU7auxbdtjARosiCbXehJnjvWx4Ichbmf/0aBm06HQzhwTtyWFEastFRRQUAARsTPfggKr4SW+yNFYcBuP7/uBkaD2JyTf2nuW+KFI/F6o6n7vc+JeTJW9dbF9Z/67a6PsqotSUxdjYK/OHN+/lJF9u9G5JP3Xtj4W56Pte9myu85+cJNqdNG4grLv/SkutPeqpNDOnGvqreayuzbK7rpo8H+N0b1TEX1LO9K31GoejWscNfUxNu2o5ZMdNXyyo4Y9tVE6lRTSqShCpxKrMXQujhApEHbURK02sKehVrBjb5SiQrEf8+AHPVHr7pL8GSgppGsHqyHWRuN8Um01so+rG2po1XvrKQxqqlbzbbhfEJz4RIL/Z6J2WFJYQElRhA6NbgWC/7MSi8eD24bax56g9mD3o9RF4xRGCigqsBq3vbZQHInQrWPhvtp7onWjW8eifZ/RxMdBgs/JzpooVTtrqdpZy6adNcFtLTV1MToWR+hUbO9Ph+C2MFJAfVCz3VerD2p0+7VOFNj9AhFKiiJBbTeyr2bXqThCSWEBRYX7f48Sn5N88JpQM/kEps451zw+galzzrmDkgch55xzoclrEBKRySKyQkQqReSGFM+XiMjs4Pm3RGRw0nM3BstXiMg5TZUpIn8SkTUisjj4GxMsnygi1UnLb8p2/5xzzuVX3hITRCQC3AGcBawHFojIXFVdnrTalcA2VR0mItOB24ALRWQkdpXVUcBRwPMiMiLYJlOZP1TVOSl25xVV/UIO++eccy6P8lkTGgdUqupqVa0DZgFTG60zFbg3uD8HOFMsbWgqMEtVa1V1DVAZlJdNma25f8455/Ion0GoH7Au6fH6YFnKdVQ1ClQDvTJs21SZt4jIOyLySxEpSVo+QUSWiMhTIjKqGfsHgIhcLSIVIlJRVVWV9oCdc841T3tKTLgROBY4CegJXB8sXwQMUtXRwG+Ax5pbsKrOVNVyVS0vKytrrf11zrnDXj6D0AYgeRRm/2BZynVEpBAoBbZk2DZtmar6sZpa4B6suQ1V3aGqu4L7TwJFItI7y/1zzjmXR/mcMWEBMFxEhmA/7tOBrzVaZy5wOfAGMA2Yp6oqInOBB0Tkv7HEhOHAfGxAccoyRaSvqn4c9CmdD7wbLD8S2BiUOw4LvFuA7Vns3wEWLly4WUQ+yPE96Q1sznHbQ5kf9+HFj/vwks1xD0r3RN6CkKpGReRa4BkgAtytqstE5GagQlXnAncB94lIJbAVCwQE6z0ELAeiwAxVjQGkKjN4yftFpAwLVIuBbwXLpwHXiEgU2AtMV5smIuX+ZXFcObfHiUhFulHD7Zkf9+HFj/vw0tLj9ml72pB/SA8vftyHFz/u3LSnxATnnHOHGA9CbWtm2DsQEj/uw4sf9+GlRcftzXHOOedC4zUh55xzofEg5JxzLjQehNrA4TRbt4jcLSKbROTdpGU9ReQ5EVkV3PYIcx9bm4gMEJEXRWS5iCwTkeuC5e36uAFEpIOIzA+mxVomIv8ZLB8SzIxfGcyUXxz2vrY2EYmIyNsi8tfgcbs/ZgARWSsiS4OrElQEy3L+rHsQyrOk2bqnACOBi4JZwturPwGTGy27AXhBVYcDLwSP25Mo8H1VHQmMB2YE/+P2ftwAtcBng2mxxgCTRWQ8NiP+L1V1GLANmzG/vbkOeC/p8eFwzAmTVHVMUmp2zp91D0L5d1jN1q2qf8cGHidLni39XmxGi3YjmDJqUXB/J/bD1I92ftwAwVRZu4KHRcGfAp/FZsaHdnjsItIf+Dzwx+Cx0M6PuQk5f9Y9COVf1rN1t2N9VPXj4P4nQJ8wdyafxC7MeALwFofJcQfNUouBTcBzwPvA9mBmfGifn/lfAf8KxIPHvWj/x5ygwLMislBErg6W5fxZz+fccc4dIJjDr12OCxCRLsDDwHdUdYedHJv2fNzBlFpjRKQ78Cg2m327JSJfADap6kIRmRj2/oTgNFXdICJHAM+JyD+Sn2zuZ91rQvnns3XDRhHpCzbRLHbG3K6ISBEWgO5X1UeCxe3+uJOp6nbgRWAC0D2YGR/a32f+VOCLIrIWa17/LPA/tO9j3kdVE1cu2ISddIyjBZ91D0L5t2828SBbZjo2e/jhJDFbOsHt4yHuS6sL+gPuAt5T1f9OeqpdHzeAiJQFNSBEpCNwFtYn9iI2eTC0s2NX1RtVtb+qDsa+z/NU9WLa8TEniEhnEemauA+cjV2xIOfPus+Y0AZE5FysDTkxW/ctIe9S3ojIg8BEbHr3jcBPsAsJPgQMBD4AvqqqjZMXDlkichrwCrCUhj6CH2H9Qu32uAFE5HisIzqCndQ+pKo3i8hQrJbQE3gbuCS41le7EjTH/UBVv3A4HHNwjI8GDwuBB1T1FhHpRY6fdQ9CzjnnQuPNcc4550LjQcg551xoPAg555wLjQch55xzofEg5JxzLjQehJw7TIjIxMSMz84dLDwIOeecC40HIecOMiJySXCNnsUicmcwQeguEfllcM2eF0SkLFh3jIi8KSLviMijieu4iMgwEXk+uM7PIhE5Oii+i4jMEZF/iMj9kjzBnXMh8CDk3EFERD4FXAicqqpjgBhwMdAZqFDVUcDL2EwUAH8GrlfV47EZGxLL7wfuCK7zcwqQmOH4BOA72LWthmLzoDkXGp9F27mDy5nAicCCoJLSEZsMMg7MDtb5P+ARESkFuqvqy8Hye4G/BHN79VPVRwFUtQYgKG++qq4PHi8GBgOv5v+wnEvNg5BzBxcB7lXVG/dbKPLvjdbLdb6t5LnMYvhvgAuZN8c5d3B5AZgWXKsFEekpIoOw72pihuavAa+qajWwTUROD5ZfCrwcXN11vYicH5RRIiKd2vQonMuSnwU5dxBR1eUi8mPsypUFQD0wA9gNjAue24T1G4FNm//7IMisBq4Ill8K3CkiNwdlfKUND8O5rPks2s4d07lPpwAAAEFJREFUAkRkl6p2CXs/nGtt3hznnHMuNF4Tcs45FxqvCTnnnAuNByHnnHOh8SDknHMuNB6EnHPOhcaDkHPOudD8f3eOxzTxBrmvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(log_train[0][1:], log_train[1][1:])\n",
    "plt.plot(log_eval[0][1:], log_eval[1][1:])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "The trained model will be used to make predictions on the submitted data.  \n",
    "`DataFrame` → `Ndarray` → `tensor` and transform the data to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Perform data preparation for submission from `jpx_tokyo_market_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: compiletime version 3.7 of module 'jpx_tokyo_market_prediction.competition' does not match runtime version 3.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/d/dataset/quant/kaggle22/\")\n",
    "\n",
    "import jpx_tokyo_market_prediction\n",
    "env = jpx_tokyo_market_prediction.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([464, 30, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15229/3863093181.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['target'] = y_pred\n",
      "/tmp/ipykernel_15229/3863093181.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['Rank'] = pred_df[\"target\"].rank(ascending=False, method=\"first\") - 1\n",
      "/tmp/ipykernel_15229/3863093181.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['Rank'] = pred_df['Rank'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([512, 30, 5])\n",
      "input size torch.Size([464, 30, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15229/3863093181.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['target'] = y_pred\n",
      "/tmp/ipykernel_15229/3863093181.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['Rank'] = pred_df[\"target\"].rank(ascending=False, method=\"first\") - 1\n",
      "/tmp/ipykernel_15229/3863093181.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pred_df['Rank'] = pred_df['Rank'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n",
    "    prices = prices.fillna(0)\n",
    "    prices['SupervisionFlag'] = prices['SupervisionFlag'].map({True: 1, False: 0})\n",
    "    prices['Date'] = pd.to_datetime(prices['Date'])\n",
    "    pred_df = predict(model, prices)\n",
    "    # print(pred_df)\n",
    "    env.predict(pred_df)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>1301</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>1332</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>1333</td>\n",
       "      <td>1331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>1375</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>1376</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>9990</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>9991</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>9993</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>9994</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>9997</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  SecuritiesCode  Rank\n",
       "0    2021-12-07            1301  1561\n",
       "1    2021-12-07            1332    19\n",
       "2    2021-12-07            1333  1331\n",
       "3    2021-12-07            1375   722\n",
       "4    2021-12-07            1376   825\n",
       "...         ...             ...   ...\n",
       "1995 2021-12-07            9990   253\n",
       "1996 2021-12-07            9991   440\n",
       "1997 2021-12-07            9993   996\n",
       "1998 2021-12-07            9994  1378\n",
       "1999 2021-12-07            9997   300\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-showcode": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
